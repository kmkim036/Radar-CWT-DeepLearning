{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as tr\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from pytorchtools import EarlyStopping\n",
    "#from pytorchtools import EarlyStopping_acc\n",
    "from torchsummary import summary as summary_\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Function\n",
    "from binarized_modules import  BinarizeLinear,BinarizeConv2d\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(a, bit=7):\n",
    "    quant = a*(2**bit)\n",
    "    quant = quant.round()\n",
    "    quant /= 2**bit\n",
    "    return quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(person,motion): # person, motion에 해당하는 image 불러옴\n",
    "    date = '220132'\n",
    "#    file_name = '_cwt.txt'\n",
    "    file_name = '_stft.txt'\n",
    "    DirectoryPath = 'C:/Users/hojung/Documents/Anaconda_python/data/class12/'\n",
    "    whole_count = 100\n",
    "#    image = np.zeros(shape=(whole_count, 81, 1920, 1))\n",
    "    image = np.zeros(shape=(whole_count, 128, 29, 1))\n",
    "    label = []\n",
    "    cwt_data = pd.read_csv(\n",
    "                DirectoryPath + date + \"_\" + str(person) + \"_\" + str(motion) + file_name)\n",
    "    for i in range(0, whole_count):\n",
    "        df = np.fromstring(cwt_data['pixels'][i], dtype=int, sep=' ')\n",
    "#        df = np.reshape(df, (81, 1920, 1))\n",
    "        df = np.reshape(df, (128, 29, 1))\n",
    "        image[i] = df\n",
    "        label.append(person-1)    # 사람으로 구분\n",
    "    return image, label\n",
    "\n",
    "\n",
    "\n",
    "# 시작과 끝 좌표는 scale한 후의 좌표를 기준으로 함\n",
    "def preprocessing_resize_crop(image,start_row,end_row,start_col,end_col,row_scale,col_scale): \n",
    "    crop_image = image[:,0:image.shape[1]:row_scale,0:image.shape[2]:col_scale]\n",
    "    crop_image = crop_image[:,start_row:end_row,start_col:end_col]\n",
    "    return crop_image\n",
    "\n",
    "def concatenate_n_div(image0, label0, image1, label1, image2, label2, image3, label3): # ratio비율로 각 data set을 합치고 순서도 섞음\n",
    "    \n",
    "\n",
    "    count = 100\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    test_ratio = 0.15 # 적용안됨\n",
    "    \n",
    "    x_train = np.concatenate((image0[0:int(count*train_ratio)], image1[0:int(count*train_ratio)], image2[0:int(count*train_ratio)],\n",
    "                              image3[0:int(count*train_ratio)]))\n",
    "    y_train = np.concatenate((label0[0:int(count*train_ratio)], label1[0:int(count*train_ratio)], label2[0:int(count*train_ratio)],\n",
    "                              label3[0:int(count*train_ratio)]))\n",
    "    x_val = np.concatenate((image0[int(count*train_ratio) : int(count*train_ratio + count*val_ratio)],\n",
    "                            image1[int(count*train_ratio) : int(count*train_ratio + count*val_ratio)],\n",
    "                            image2[int(count*train_ratio) : int(count*train_ratio + count*val_ratio)],\n",
    "                            image3[int(count*train_ratio) : int(count*train_ratio + count*val_ratio)]))\n",
    "    y_val = np.concatenate((label0[int(count*train_ratio) : int(count*train_ratio + count*val_ratio)],\n",
    "                            label1[int(count*train_ratio) : int(count*train_ratio + count*val_ratio)],\n",
    "                            label2[int(count*train_ratio) : int(count*train_ratio + count*val_ratio)],\n",
    "                            label3[int(count*train_ratio) : int(count*train_ratio + count*val_ratio)]))\n",
    "    x_test = np.concatenate((image0[int(count*train_ratio + count*val_ratio) : count],\n",
    "                             image1[int(count*train_ratio + count*val_ratio) : count],\n",
    "                             image2[int(count*train_ratio + count*val_ratio) : count],\n",
    "                             image3[int(count*train_ratio + count*val_ratio) : count]))\n",
    "    y_test = np.concatenate((label0[int(count*train_ratio + count*val_ratio) : count],\n",
    "                             label1[int(count*train_ratio + count*val_ratio) : count],\n",
    "                             label2[int(count*train_ratio + count*val_ratio) : count],\n",
    "                             label3[int(count*train_ratio + count*val_ratio) : count]))\n",
    "    \n",
    "    s = np.arange(x_train.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    x_train = x_train[s]\n",
    "    y_train = y_train[s]\n",
    "\n",
    "    s = np.arange(x_val.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    x_val = x_val[s]\n",
    "    y_val = y_val[s]\n",
    "\n",
    "    s = np.arange(x_test.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    x_test = x_test[s]\n",
    "    y_test = y_test[s]\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "class TensorData(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.x_data = self.x_data.permute(0,3,1,2) # 이미지 개수, 채널 수, 이미지 너비, 높이\n",
    "        self.y_data = torch.LongTensor(y_data)\n",
    "        self.len = self.y_data.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(Net,self).__init__()\n",
    "        self.infl_ratio=3;\n",
    "        self.channel = 16;\n",
    "        self.features = nn.Sequential(\n",
    "            # BinarizeConv2d(입력 채널수, 출력 채널수, 커널 사이즈, 스트라이드, 패딩)\n",
    "            BinarizeConv2d(1, self.channel*self.infl_ratio,kernel_size=3,stride=1,padding=0),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1),\n",
    "            # nn.BatchNorm2d(입출력 채널수)\n",
    "            nn.BatchNorm2d(self.channel*self.infl_ratio),\n",
    "            nn.Hardtanh(),\n",
    "\n",
    "            BinarizeConv2d(self.channel*self.infl_ratio, self.channel*self.infl_ratio,kernel_size=3,stride=1,padding=0),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(self.channel*self.infl_ratio),\n",
    "            nn.Hardtanh(),\n",
    "\n",
    "            BinarizeConv2d(self.channel*self.infl_ratio, self.channel*self.infl_ratio,kernel_size=3,stride=1,padding=0),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(self.channel*self.infl_ratio),\n",
    "            nn.Hardtanh(),\n",
    "\n",
    "            BinarizeConv2d(self.channel*self.infl_ratio, self.channel,kernel_size=3,stride=1,padding=0),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(self.channel),\n",
    "            nn.Hardtanh()\n",
    "\n",
    "         )\n",
    "            \n",
    "        self.classifier = nn.Sequential(\n",
    "            # BinarizeLinear(입력 dense길이, 출력 dense길이)\n",
    "            BinarizeLinear(self.channel*20*12,32),\n",
    "            BinarizeLinear(32,num_classes)\n",
    "        )\n",
    "        self.softmax = nn.Softmax()\n",
    "                \n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1,self.channel*20*12)\n",
    "        x = self.classifier(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(Net2,self).__init__()\n",
    "        self.infl_ratio=3;\n",
    "        \n",
    "            # BinarizeConv2d(입력 채널수, 출력 채널수, 커널 사이즈, 스트라이드, 패딩)\n",
    "        self.conv_L1 = BinarizeConv2d(1, 16*self.infl_ratio,kernel_size=3,stride=1,padding='same')\n",
    "        self.max_L1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_L1 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_L1 = nn.Hardtanh()\n",
    "        self.conv_R1 = BinarizeConv2d(1, 16*self.infl_ratio,kernel_size=5,stride=1,padding='same')\n",
    "        self.max_R1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_R1 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_R1 = nn.Hardtanh()\n",
    "\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "\n",
    "        self.conv_L2 = BinarizeConv2d(16*self.infl_ratio, 16*self.infl_ratio,kernel_size=3,stride=1,padding='same')\n",
    "        self.max_L2 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_L2 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_L2 = nn.Hardtanh()\n",
    "        self.conv_R2 = BinarizeConv2d(16*self.infl_ratio, 16*self.infl_ratio,kernel_size=5,stride=1,padding='same')\n",
    "        self.max_R2 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_R2 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_R2 = nn.Hardtanh()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc1 = BinarizeLinear(48*33*25,64)\n",
    "        self.human = BinarizeLinear(64,4)\n",
    "         \n",
    "            \n",
    "        \n",
    "        self.softmax2 = nn.Softmax()\n",
    "                \n",
    "                \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_L1(x)\n",
    "        x1 = self.max_L1(x1)\n",
    "        x1 = self.bn_L1(x1)\n",
    "        x1 = self.htan_L1(x1)\n",
    "\n",
    "        x2 = self.conv_R1(x)\n",
    "        x2 = self.max_R1(x2)\n",
    "        x2 = self.bn_R1(x2)\n",
    "        x2 = self.htan_R1(x2)\n",
    "\n",
    "        x3 = torch.add(x1,x2)\n",
    "        x3 = self.max1(x3)\n",
    "\n",
    "        x4 = self.conv_L2(x3)\n",
    "        x4 = self.max_L2(x4)\n",
    "        x4 = self.bn_L2(x4)\n",
    "        x4 = self.htan_L2(x4)\n",
    "\n",
    "        x5 = self.conv_R2(x3)\n",
    "        x5 = self.max_R2(x5)\n",
    "        x5 = self.bn_R2(x5)\n",
    "        x5 = self.htan_R2(x5)\n",
    "\n",
    "        x6 = torch.add(x4,x5)\n",
    "\n",
    "        x6 = x6.view(-1,48*33*25)\n",
    "        x6 = self.fc1(x6)\n",
    "        human = self.softmax2(self.human(x6))\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        return human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net3(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(Net3,self).__init__()\n",
    "        self.infl_ratio=3;\n",
    "        \n",
    "            # BinarizeConv2d(입력 채널수, 출력 채널수, 커널 사이즈, 스트라이드, 패딩)\n",
    "        self.conv_L1 = BinarizeConv2d(1, 16*self.infl_ratio,kernel_size=3,stride=1,padding=0)\n",
    "        self.max_L1 = nn.MaxPool2d(kernel_size=3, stride=1)\n",
    "        self.bn_L1 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_L1 = nn.Hardtanh()\n",
    "        # self.conv_R1 = BinarizeConv2d(1, 16*self.infl_ratio,kernel_size=5,stride=1,padding='same')\n",
    "        # self.max_R1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        # self.bn_R1 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        # self.htan_R1 = nn.Hardtanh()\n",
    "\n",
    "        # self.max1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "\n",
    "        self.conv_L2 = BinarizeConv2d(16*self.infl_ratio, 16*self.infl_ratio,kernel_size=3,stride=1,padding=0)\n",
    "        self.max_L2 = nn.MaxPool2d(kernel_size=3, stride=1)\n",
    "        self.bn_L2 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_L2 = nn.Hardtanh()\n",
    "        # self.conv_R2 = BinarizeConv2d(16*self.infl_ratio, 16*self.infl_ratio,kernel_size=5,stride=1,padding='same')\n",
    "        # self.max_R2 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        # self.bn_R2 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        # self.htan_R2 = nn.Hardtanh()\n",
    "        \n",
    "        \n",
    "        self.fc1 = BinarizeLinear(48*28*20,128)\n",
    "        self.human = BinarizeLinear(128,4)\n",
    "         \n",
    "            \n",
    "        \n",
    "        self.softmax2 = nn.Softmax()\n",
    "                \n",
    "                \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_L1(x)\n",
    "        x1 = self.max_L1(x1)\n",
    "        x1 = self.bn_L1(x1)\n",
    "        x1 = self.htan_L1(x1)\n",
    "        \n",
    "        # x2 = self.conv_R1(x)\n",
    "        # x2 = self.max_R1(x2)\n",
    "        # x2 = self.bn_R1(x2)\n",
    "        # x2 = self.htan_R1(x2)\n",
    "\n",
    "        # x3 = torch.add(x1,x2)\n",
    "        # x3 = self.max1(x3)\n",
    "\n",
    "        x1 = self.conv_L2(x1)\n",
    "        x1 = self.max_L2(x1)\n",
    "        x1 = self.bn_L2(x1)\n",
    "        x1 = self.htan_L2(x1)\n",
    "        \n",
    "        # x5 = self.conv_R2(x3)\n",
    "        # x5 = self.max_R2(x5)\n",
    "        # x5 = self.bn_R2(x5)\n",
    "        # x5 = self.htan_R2(x5)\n",
    "\n",
    "        \n",
    "\n",
    "        x1 = x1.view(-1,48*28*20)\n",
    "        x1 = self.fc1(x1)\n",
    "        human = self.softmax2(self.human(x1))\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        return human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(Net2,self).__init__()\n",
    "        self.infl_ratio=3;\n",
    "        \n",
    "            # BinarizeConv2d(입력 채널수, 출력 채널수, 커널 사이즈, 스트라이드, 패딩)\n",
    "        self.conv_L1 = BinarizeConv2d(1, 16*self.infl_ratio,kernel_size=3,stride=1,padding='same')\n",
    "        self.max_L1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_L1 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_L1 = nn.Hardtanh()\n",
    "        self.conv_R1 = BinarizeConv2d(1, 16*self.infl_ratio,kernel_size=5,stride=1,padding='same')\n",
    "        self.max_R1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_R1 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_R1 = nn.Hardtanh()\n",
    "\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "\n",
    "        self.conv_L2 = BinarizeConv2d(16*self.infl_ratio, 16*self.infl_ratio,kernel_size=3,stride=1,padding='same')\n",
    "        self.max_L2 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_L2 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_L2 = nn.Hardtanh()\n",
    "        self.conv_R2 = BinarizeConv2d(16*self.infl_ratio, 16*self.infl_ratio,kernel_size=5,stride=1,padding='same')\n",
    "        self.max_R2 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_R2 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_R2 = nn.Hardtanh()\n",
    "        \n",
    "        self.max2 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "\n",
    "        self.conv_L3 = BinarizeConv2d(16*self.infl_ratio, 16*self.infl_ratio,kernel_size=3,stride=1,padding='same')\n",
    "        self.max_L3 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_L3 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_L3 = nn.Hardtanh()\n",
    "        self.conv_R3 = BinarizeConv2d(16*self.infl_ratio, 16*self.infl_ratio,kernel_size=5,stride=1,padding='same')\n",
    "        self.max_R3 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_R3 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_R3 = nn.Hardtanh()\n",
    "        \n",
    "        self.max3 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        \n",
    "        self.fc1 = BinarizeLinear(48*30*22,128)\n",
    "        self.human = BinarizeLinear(128,4)\n",
    "        #self.motion = BinarizeLinear(128,3)\n",
    "            \n",
    "        self.softmax1 = nn.Softmax()\n",
    "        self.softmax2 = nn.Softmax()\n",
    "                \n",
    "                \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_L1(x)\n",
    "        x1 = self.max_L1(x1)\n",
    "        x1 = self.bn_L1(x1)\n",
    "        x1 = self.htan_L1(x1)\n",
    "\n",
    "        x2 = self.conv_R1(x)\n",
    "        x2 = self.max_R1(x2)\n",
    "        x2 = self.bn_R1(x2)\n",
    "        x2 = self.htan_R1(x2)\n",
    "\n",
    "        x3 = torch.add(x1,x2)\n",
    "        x3 = self.max1(x3)\n",
    "\n",
    "        x4 = self.conv_L2(x3)\n",
    "        x4 = self.max_L2(x4)\n",
    "        x4 = self.bn_L2(x4)\n",
    "        x4 = self.htan_L2(x4)\n",
    "\n",
    "        x5 = self.conv_R2(x3)\n",
    "        x5 = self.max_R2(x5)\n",
    "        x5 = self.bn_R2(x5)\n",
    "        x5 = self.htan_R2(x5)\n",
    "\n",
    "        x6 = torch.add(x4,x5)\n",
    "        x6 = self.max2(x6)\n",
    "        \n",
    "        x7 = self.conv_L3(x6)\n",
    "        x7 = self.max_L3(x7)\n",
    "        x7 = self.bn_L3(x7)\n",
    "        x7 = self.htan_L3(x7)\n",
    "\n",
    "        x8 = self.conv_R3(x6)\n",
    "        x8 = self.max_R3(x8)\n",
    "        x8 = self.bn_R3(x8)\n",
    "        x8 = self.htan_R3(x8)\n",
    "\n",
    "        x9 = torch.add(x7,x8)\n",
    "        x9 = self.max3(x9)\n",
    "        \n",
    "        x9 = x9.view(-1,48*30*22)\n",
    "        x9 = self.fc1(x9)\n",
    "        human = self.softmax2(self.human(x9))\n",
    "        #motion = self.softmax1(self.motion(x9))\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        return human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "    BinarizeConv2d-1           [32, 48, 34, 26]             480\n",
      "         MaxPool2d-2           [32, 48, 32, 24]               0\n",
      "       BatchNorm2d-3           [32, 48, 32, 24]              96\n",
      "          Hardtanh-4           [32, 48, 32, 24]               0\n",
      "    BinarizeConv2d-5           [32, 48, 30, 22]          20,784\n",
      "         MaxPool2d-6           [32, 48, 28, 20]               0\n",
      "       BatchNorm2d-7           [32, 48, 28, 20]              96\n",
      "          Hardtanh-8           [32, 48, 28, 20]               0\n",
      "    BinarizeLinear-9                  [32, 128]       3,440,768\n",
      "   BinarizeLinear-10                    [32, 4]             516\n",
      "          Softmax-11                    [32, 4]               0\n",
      "================================================================\n",
      "Total params: 3,462,740\n",
      "Trainable params: 3,462,740\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 64.81\n",
      "Params size (MB): 13.21\n",
      "Estimated Total Size (MB): 78.15\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_22128/3398403732.py:65: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  human = self.softmax2(self.human(x1))\n"
     ]
    }
   ],
   "source": [
    "net = Net3().to(device)\n",
    "summary_(net,(1,36,28),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device), \n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for p in list(model.parameters()):\n",
    "            if hasattr(p,'org'):\n",
    "                p.data.copy_(p.org)\n",
    "        optimizer.step()\n",
    "        for p in list(model.parameters()):\n",
    "            if hasattr(p,'org'):\n",
    "                p.org.copy_(p.data.clamp_(-1,1))\n",
    "                \n",
    "        if batch % 40 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred,y)\n",
    "            test_loss += loss.item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy_human: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    return 100*correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALE:16 /1초 추출 + 0.2초 씩 이동 / row 30\n",
    "#=========================================================\n",
    "#================파라미터 설정==========================\n",
    "#============================================================\n",
    "# STFT = (128, 29) //  CWT = (81,1920)\n",
    "# 좌표는 스케일 이후 범위\n",
    "start_row = 46\n",
    "end_row = 82\n",
    "scale_row = 1\n",
    "rows = 128\n",
    "\n",
    "start_col = 0\n",
    "end_col = 28\n",
    "scale_col = 1\n",
    "cols = 29\n",
    "\n",
    "aug = 1  # 1이면 augmentation 0이면 X\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "                         width_shift_range=0.2\n",
    "                            )\n",
    "\n",
    "\n",
    "motion = 2  # 추출 모션\n",
    "\n",
    "image1,label1 = preprocessing(1,motion) # 성진_motion 불러옴\n",
    "image2,label2 = preprocessing(2,motion) # 호정_motion 불러옴\n",
    "image3,label3 = preprocessing(3,motion) # 경민_motion 불러옴\n",
    "image4,label4 = preprocessing(4,motion) # 경민_motion 불러옴\n",
    "\n",
    "# 정규화 추가\n",
    "total_img = np.concatenate((image1, image2, image3, image4))\n",
    "total_std = total_img.std()\n",
    "total_mean = total_img.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total try_num 1, Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_22128/3398403732.py:65: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  human = self.softmax2(self.human(x1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.418067  [    0/ 2800]\n",
      "loss: 0.943058  [ 1280/ 2800]\n",
      "loss: 1.066112  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 75.0%, Avg loss: 0.032721 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 78.3%, Avg loss: 0.031604 \n",
      "\n",
      "total try_num 1, Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.037947  [    0/ 2800]\n",
      "loss: 1.042027  [ 1280/ 2800]\n",
      "loss: 1.033403  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 86.7%, Avg loss: 0.029733 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 83.3%, Avg loss: 0.030479 \n",
      "\n",
      "total try_num 1, Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.911209  [    0/ 2800]\n",
      "loss: 0.994124  [ 1280/ 2800]\n",
      "loss: 1.009264  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 78.3%, Avg loss: 0.031748 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 88.3%, Avg loss: 0.028332 \n",
      "\n",
      "total try_num 1, Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.865092  [    0/ 2800]\n",
      "loss: 0.871850  [ 1280/ 2800]\n",
      "loss: 0.933908  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 86.7%, Avg loss: 0.029930 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 91.7%, Avg loss: 0.027561 \n",
      "\n",
      "total try_num 1, Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.864004  [    0/ 2800]\n",
      "loss: 0.868522  [ 1280/ 2800]\n",
      "loss: 0.850484  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 81.7%, Avg loss: 0.030871 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 90.0%, Avg loss: 0.028123 \n",
      "\n",
      "total try_num 1, Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.961331  [    0/ 2800]\n",
      "loss: 0.944066  [ 1280/ 2800]\n",
      "loss: 0.837792  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 85.0%, Avg loss: 0.030361 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 90.0%, Avg loss: 0.027708 \n",
      "\n",
      "total try_num 1, Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.837417  [    0/ 2800]\n",
      "loss: 0.801505  [ 1280/ 2800]\n",
      "loss: 0.774973  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 86.7%, Avg loss: 0.029239 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 86.7%, Avg loss: 0.028492 \n",
      "\n",
      "total try_num 1, Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.820213  [    0/ 2800]\n",
      "loss: 0.819806  [ 1280/ 2800]\n",
      "loss: 0.819419  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 85.0%, Avg loss: 0.030099 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 93.3%, Avg loss: 0.027198 \n",
      "\n",
      "total try_num 1, Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.837433  [    0/ 2800]\n",
      "loss: 0.819788  [ 1280/ 2800]\n",
      "loss: 0.774921  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 85.0%, Avg loss: 0.029284 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 86.7%, Avg loss: 0.029123 \n",
      "\n",
      "total try_num 1, Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.813952  [    0/ 2800]\n",
      "loss: 0.867994  [ 1280/ 2800]\n",
      "loss: 0.836365  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 83.3%, Avg loss: 0.030129 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 88.3%, Avg loss: 0.028556 \n",
      "\n",
      "total try_num 2, Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.398389  [    0/ 2800]\n",
      "loss: 1.069398  [ 1280/ 2800]\n",
      "loss: 0.984984  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 76.7%, Avg loss: 0.032391 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 76.7%, Avg loss: 0.033015 \n",
      "\n",
      "total try_num 2, Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.047690  [    0/ 2800]\n",
      "loss: 0.882116  [ 1280/ 2800]\n",
      "loss: 1.014348  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 81.7%, Avg loss: 0.030949 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 78.3%, Avg loss: 0.032117 \n",
      "\n",
      "total try_num 2, Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.947277  [    0/ 2800]\n",
      "loss: 0.870579  [ 1280/ 2800]\n",
      "loss: 0.926430  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 85.0%, Avg loss: 0.028889 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 83.3%, Avg loss: 0.030531 \n",
      "\n",
      "total try_num 2, Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.848294  [    0/ 2800]\n",
      "loss: 0.777658  [ 1280/ 2800]\n",
      "loss: 0.913054  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 80.0%, Avg loss: 0.030711 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 80.0%, Avg loss: 0.031402 \n",
      "\n",
      "total try_num 2, Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.898746  [    0/ 2800]\n",
      "loss: 0.906649  [ 1280/ 2800]\n",
      "loss: 0.867988  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 85.0%, Avg loss: 0.029814 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 86.7%, Avg loss: 0.028898 \n",
      "\n",
      "total try_num 2, Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.863890  [    0/ 2800]\n",
      "loss: 0.851112  [ 1280/ 2800]\n",
      "loss: 0.819416  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 80.0%, Avg loss: 0.031537 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 81.7%, Avg loss: 0.030988 \n",
      "\n",
      "total try_num 2, Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.806149  [    0/ 2800]\n",
      "loss: 0.870726  [ 1280/ 2800]\n",
      "loss: 0.788551  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 78.3%, Avg loss: 0.031455 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 88.3%, Avg loss: 0.028568 \n",
      "\n",
      "total try_num 2, Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.788225  [    0/ 2800]\n",
      "loss: 0.775329  [ 1280/ 2800]\n",
      "loss: 0.837071  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 83.3%, Avg loss: 0.030501 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 83.3%, Avg loss: 0.029984 \n",
      "\n",
      "total try_num 2, Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.837080  [    0/ 2800]\n",
      "loss: 0.871308  [ 1280/ 2800]\n",
      "loss: 0.877617  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 80.0%, Avg loss: 0.031187 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 81.7%, Avg loss: 0.030850 \n",
      "\n",
      "total try_num 2, Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.744171  [    0/ 2800]\n",
      "loss: 0.743668  [ 1280/ 2800]\n",
      "loss: 0.777705  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 81.7%, Avg loss: 0.030952 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 83.3%, Avg loss: 0.030440 \n",
      "\n",
      "total try_num 3, Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.341872  [    0/ 2800]\n",
      "loss: 1.209078  [ 1280/ 2800]\n",
      "loss: 1.161217  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 81.7%, Avg loss: 0.030479 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 80.0%, Avg loss: 0.032068 \n",
      "\n",
      "total try_num 3, Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.925803  [    0/ 2800]\n",
      "loss: 1.064678  [ 1280/ 2800]\n",
      "loss: 0.965538  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 73.3%, Avg loss: 0.033274 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 83.3%, Avg loss: 0.030516 \n",
      "\n",
      "total try_num 3, Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.055410  [    0/ 2800]\n",
      "loss: 0.806190  [ 1280/ 2800]\n",
      "loss: 0.900701  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 86.7%, Avg loss: 0.029502 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 83.3%, Avg loss: 0.030909 \n",
      "\n",
      "total try_num 3, Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.020207  [    0/ 2800]\n",
      "loss: 0.921781  [ 1280/ 2800]\n",
      "loss: 0.866215  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 91.7%, Avg loss: 0.027761 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 85.0%, Avg loss: 0.029823 \n",
      "\n",
      "total try_num 3, Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.961459  [    0/ 2800]\n",
      "loss: 0.913601  [ 1280/ 2800]\n",
      "loss: 0.992082  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 95.0%, Avg loss: 0.026676 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 86.7%, Avg loss: 0.028776 \n",
      "\n",
      "total try_num 3, Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.867981  [    0/ 2800]\n",
      "loss: 0.788450  [ 1280/ 2800]\n",
      "loss: 0.870625  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 81.7%, Avg loss: 0.030659 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 88.3%, Avg loss: 0.029272 \n",
      "\n",
      "total try_num 3, Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.923256  [    0/ 2800]\n",
      "loss: 0.819701  [ 1280/ 2800]\n",
      "loss: 0.808181  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 90.0%, Avg loss: 0.028209 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 86.7%, Avg loss: 0.028997 \n",
      "\n",
      "total try_num 3, Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.895257  [    0/ 2800]\n",
      "loss: 0.868319  [ 1280/ 2800]\n",
      "loss: 0.806223  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 95.0%, Avg loss: 0.026497 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 91.7%, Avg loss: 0.027591 \n",
      "\n",
      "total try_num 3, Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.808957  [    0/ 2800]\n",
      "loss: 0.806169  [ 1280/ 2800]\n",
      "loss: 0.774972  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 93.3%, Avg loss: 0.026692 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 90.0%, Avg loss: 0.028011 \n",
      "\n",
      "total try_num 3, Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.837425  [    0/ 2800]\n",
      "loss: 0.806231  [ 1280/ 2800]\n",
      "loss: 0.806230  [ 2560/ 2800]\n",
      "Test Error: \n",
      " Accuracy_human: 88.3%, Avg loss: 0.028623 \n",
      "\n",
      "Test Error: \n",
      " Accuracy_human: 88.3%, Avg loss: 0.028199 \n",
      "\n",
      "Done!\n",
      "동작시간 : 0:00:18.473766\n",
      "try : 1 // epoch : 4 // Max_average_accuracy = 89.2, Max_accuray_valid_human = 86.7, Max_accuray_test_human = 91.7\n",
      " \n",
      "try : 2 // epoch : 5 // Max_average_accuracy = 85.8, Max_accuray_valid_human = 85.0, Max_accuray_test_human = 86.7\n",
      " \n",
      "try : 3 // epoch : 8 // Max_average_accuracy = 93.3, Max_accuray_valid_human = 95.0, Max_accuray_test_human = 91.7\n",
      " \n",
      "total average_acc = 89.4\n"
     ]
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "epochs = 10  # 학습을 원하는 만큼 수정요\n",
    "try_num = 3\n",
    "human_result_acc = np.zeros(try_num*2*epochs).reshape(try_num,2,epochs)\n",
    "motion_result_acc = np.zeros(try_num*2*epochs).reshape(try_num,2,epochs)\n",
    "average_result_acc = np.zeros(try_num*epochs).reshape(try_num,epochs)\n",
    "average_acc = 0\n",
    "\n",
    "quanta = 1 # quantization 사용유무\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "for a in range(try_num):\n",
    "\n",
    "    model = Net3()\n",
    "    model.cuda()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "    \n",
    "    s = np.arange(image1.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    image1_shuff = image1[s]       # 불러온 성진_motion data의 순서를 섞음\n",
    "\n",
    "    s = np.arange(image2.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    image2_shuff = image2[s]       # 불러온 호정_motion data의 순서를 섞음\n",
    "\n",
    "    s = np.arange(image3.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    image3_shuff = image3[s]       # 불러온 3_motion data의 순서를 섞음\n",
    "\n",
    "    s = np.arange(image4.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    image4_shuff = image4[s]       # 불러온 4_motion data의 순서를 섞음\n",
    "\n",
    "    image1_crop = preprocessing_resize_crop(\n",
    "        image1_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
    "    image2_crop = preprocessing_resize_crop(\n",
    "        image2_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
    "    image3_crop = preprocessing_resize_crop(\n",
    "        image3_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
    "    image4_crop = preprocessing_resize_crop(\n",
    "        image4_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
    "\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = concatenate_n_div(\n",
    "            image1_crop, label1, image2_crop, label2, image3_crop, label3, image4_crop, label4)\n",
    "                # 자른 image를 각 data set으로 나눠서 합침\n",
    "\n",
    "    x_train = (x_train - total_mean) / total_std\n",
    "    x_val = (x_val - total_mean) / total_std\n",
    "    x_test = (x_test - total_mean) / total_std\n",
    "\n",
    "    # 보강할 학습데이터 이미지 생성\n",
    "    if aug == 1:\n",
    "        augment_ratio = 9   # 전체 데이터의 150%\n",
    "        augment_size = int(augment_ratio * x_train.shape[0])\n",
    "\n",
    "        # 전체 x_train 개수의 150% 비율만큼\n",
    "        randidx = np.random.randint(x_train.shape[0], size=augment_size)\n",
    "\n",
    "        # 임의로 선택된 데이터는 원본데이터를 참조하기 때문에\n",
    "        # 원본데이터에 영향을 줄수 있음. 그래서 copy() 함수를 통해 안전하게 복사본 만듬\n",
    "        x_augmented = x_train[randidx].copy()  \n",
    "        y_augmented = y_train[randidx].copy()\n",
    "\n",
    "        #  이미지 보강 실행\n",
    "        x_augmented, y_augmented = gen.flow(x_augmented, y_augmented, \n",
    "                                            batch_size=augment_size,\n",
    "                                            shuffle=False).next()\n",
    "\n",
    "        x_train = np.concatenate((x_train,x_augmented))\n",
    "        y_train = np.concatenate((y_train,y_augmented))\n",
    "        s = np.arange(x_train.shape[0])\n",
    "        np.random.shuffle(s)\n",
    "        x_train = x_train[s]\n",
    "        y_train = y_train[s]\n",
    "\n",
    "    if quanta == 1:\n",
    "        x_train = quantize(x_train)\n",
    "        x_val = quantize(x_val)\n",
    "        x_test = quantize(x_test)\n",
    "\n",
    "\n",
    "    train_data = TensorData(x_train,y_train)\n",
    "    test_data = TensorData(x_test,y_test)\n",
    "    valid_data = TensorData(x_val,y_val)\n",
    "    train_loader = DataLoader(train_data, batch_size = 32, shuffle =True)\n",
    "    test_loader = DataLoader(test_data, batch_size = 32, shuffle =True)\n",
    "    valid_loader = DataLoader(valid_data, batch_size = 32, shuffle =True)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"total try_num {a+1}, Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_loader, model, criterion, optimizer)\n",
    "\n",
    "        human_result_acc[a][0][t] = test(valid_loader, model, criterion)\n",
    "        human_result_acc[a][1][t] = test(test_loader, model, criterion)\n",
    "        average_result_acc[a][t] = (human_result_acc[a][0][t] + human_result_acc[a][1][t]) / 2\n",
    "print(\"Done!\")\n",
    "end = datetime.datetime.now()\n",
    "print('동작시간 :', end - start)\n",
    "for b in range(try_num):\n",
    "    print(f\"try : {b+1} // epoch : {np.argmax(average_result_acc[b])+1} // Max_average_accuracy = {max(average_result_acc[b]):0.1f},\\\n",
    " Max_accuray_valid_human = {human_result_acc[b][0][np.argmax(average_result_acc[b])]:0.1f},\\\n",
    " Max_accuray_test_human = {human_result_acc[b][1][np.argmax(average_result_acc[b])]:0.1f}\\n \")\n",
    "    average_acc += max(average_result_acc[b])\n",
    "average_acc /= try_num\n",
    "print(f\"total average_acc = {average_acc:0.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동작시간 : 0:00:18.473766\n",
      "try : 1 // epoch : 4 // Max_average_accuracy = 89.2, Max_accuray_valid_human = 86.7, Max_accuray_test_human = 91.7\n",
      " \n",
      "try : 2 // epoch : 5 // Max_average_accuracy = 85.8, Max_accuray_valid_human = 85.0, Max_accuray_test_human = 86.7\n",
      " \n",
      "try : 3 // epoch : 8 // Max_average_accuracy = 93.3, Max_accuray_valid_human = 95.0, Max_accuray_test_human = 91.7\n",
      " \n",
      "total average_acc = 89.4\n"
     ]
    }
   ],
   "source": [
    "print('동작시간 :', end - start)\n",
    "for b in range(try_num):\n",
    "    print(f\"try : {b+1} // epoch : {np.argmax(average_result_acc[b])+1} // Max_average_accuracy = {max(average_result_acc[b]):0.1f},\\\n",
    " Max_accuray_valid_human = {human_result_acc[b][0][np.argmax(average_result_acc[b])]:0.1f},\\\n",
    " Max_accuray_test_human = {human_result_acc[b][1][np.argmax(average_result_acc[b])]:0.1f}\\n \")\n",
    "print(f\"total average_acc = {average_acc:0.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_L1.weight': Parameter containing:\n",
       " tensor([[[[-1.,  1.,  1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [-1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1., -1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [ 1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1., -1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [ 1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [-1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1., -1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [ 1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [-1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1.,  1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1., -1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [ 1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1., -1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [ 1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [-1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1., -1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [ 1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1.,  1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [ 1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [-1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1.,  1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [ 1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [ 1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [ 1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1.,  1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1.,  1.],\n",
       "           [-1., -1., -1.],\n",
       "           [ 1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [-1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1., -1.],\n",
       "           [-1., -1., -1.],\n",
       "           [ 1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [ 1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1.,  1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [ 1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1., -1.],\n",
       "           [-1., -1., -1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [ 1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1., -1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1.,  1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [-1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1., -1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [-1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1., -1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [-1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1., -1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1.,  1.],\n",
       "           [-1., -1., -1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1., -1.],\n",
       "           [-1., -1., -1.],\n",
       "           [ 1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1.,  1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1.,  1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [ 1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1., -1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [ 1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1., -1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [-1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1., -1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [ 1.,  1., -1.]]]], device='cuda:0', requires_grad=True),\n",
       " 'conv_L1.bias': Parameter containing:\n",
       " tensor([-1., -1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,\n",
       "          1.,  1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
       "         -1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,\n",
       "         -1.,  1., -1., -1.,  1., -1.], device='cuda:0', requires_grad=True),\n",
       " 'bn_L1.weight': Parameter containing:\n",
       " tensor([1.0002, 1.0002, 1.0005, 0.9998, 0.9996, 1.0000, 1.0005, 1.0000, 1.0001,\n",
       "         0.9992, 0.9999, 0.9997, 1.0004, 1.0001, 1.0003, 0.9999, 0.9997, 1.0000,\n",
       "         1.0005, 0.9997, 1.0000, 0.9996, 0.9997, 1.0002, 1.0003, 1.0009, 1.0008,\n",
       "         0.9996, 0.9998, 0.9996, 0.9995, 0.9995, 0.9998, 0.9997, 0.9995, 1.0003,\n",
       "         0.9993, 0.9999, 1.0002, 0.9993, 1.0003, 1.0003, 0.9997, 1.0003, 1.0004,\n",
       "         1.0001, 0.9996, 0.9995], device='cuda:0', requires_grad=True),\n",
       " 'bn_L1.bias': Parameter containing:\n",
       " tensor([-9.6723e-05, -1.4645e-05, -2.4469e-04, -4.5434e-04, -4.9809e-04,\n",
       "          1.8151e-04,  1.0286e-04, -4.1391e-04, -9.5751e-04,  3.0590e-04,\n",
       "          1.6982e-04,  9.0193e-05,  2.2566e-04, -3.3376e-04, -2.9750e-04,\n",
       "         -5.0828e-04, -3.0138e-04,  2.6074e-04, -6.8376e-04, -8.0633e-04,\n",
       "         -3.6365e-04,  1.7429e-04,  4.0552e-04,  1.9904e-04, -2.0522e-04,\n",
       "         -6.2266e-05,  2.0208e-04, -5.7314e-06,  3.1717e-04,  5.4824e-05,\n",
       "         -6.6939e-05, -3.8453e-05, -5.3463e-05, -7.6947e-04,  1.4820e-04,\n",
       "          1.5669e-04, -6.8033e-04, -1.5508e-04,  2.3321e-05,  4.9545e-04,\n",
       "          2.5411e-04, -5.5677e-04,  2.6924e-04, -3.5458e-04, -2.8971e-04,\n",
       "          6.7763e-04, -7.9313e-04, -3.0908e-04], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'conv_L2.weight': Parameter containing:\n",
       " tensor([[[[-1.,  1., -1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [ 1.,  1.,  1.]],\n",
       " \n",
       "          [[-1.,  1.,  1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [-1.,  1., -1.]],\n",
       " \n",
       "          [[-1., -1.,  1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [-1., -1., -1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.,  1., -1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [-1., -1.,  1.]],\n",
       " \n",
       "          [[-1.,  1., -1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [ 1.,  1., -1.]],\n",
       " \n",
       "          [[ 1., -1.,  1.],\n",
       "           [-1., -1., -1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1., -1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [-1.,  1.,  1.]],\n",
       " \n",
       "          [[-1., -1., -1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [ 1.,  1.,  1.]],\n",
       " \n",
       "          [[-1.,  1.,  1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [-1., -1.,  1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.,  1.,  1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [ 1.,  1.,  1.]],\n",
       " \n",
       "          [[-1.,  1., -1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [-1.,  1.,  1.]],\n",
       " \n",
       "          [[ 1.,  1., -1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [-1., -1., -1.]],\n",
       " \n",
       "          [[-1.,  1.,  1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [ 1.,  1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [-1.,  1.,  1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.,  1.,  1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [-1., -1.,  1.]],\n",
       " \n",
       "          [[-1., -1.,  1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [-1.,  1., -1.]],\n",
       " \n",
       "          [[-1.,  1.,  1.],\n",
       "           [-1., -1., -1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [-1., -1., -1.]],\n",
       " \n",
       "          [[ 1.,  1., -1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [ 1., -1., -1.]],\n",
       " \n",
       "          [[ 1., -1.,  1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [-1.,  1., -1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1., -1.,  1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [-1.,  1.,  1.]],\n",
       " \n",
       "          [[ 1.,  1.,  1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [-1.,  1.,  1.]],\n",
       " \n",
       "          [[-1., -1., -1.],\n",
       "           [-1., -1., -1.],\n",
       "           [-1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1.,  1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [-1., -1., -1.]],\n",
       " \n",
       "          [[ 1.,  1., -1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [-1.,  1.,  1.]],\n",
       " \n",
       "          [[-1.,  1.,  1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [-1., -1.,  1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [ 1., -1.,  1.]],\n",
       " \n",
       "          [[ 1., -1.,  1.],\n",
       "           [-1., -1., -1.],\n",
       "           [ 1.,  1., -1.]],\n",
       " \n",
       "          [[-1.,  1., -1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1., -1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [ 1.,  1., -1.]],\n",
       " \n",
       "          [[-1.,  1., -1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [-1.,  1., -1.]],\n",
       " \n",
       "          [[ 1.,  1., -1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [ 1., -1.,  1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.,  1., -1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [-1., -1., -1.]],\n",
       " \n",
       "          [[ 1., -1.,  1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [ 1.,  1.,  1.]],\n",
       " \n",
       "          [[ 1., -1., -1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [-1.,  1., -1.]]]], device='cuda:0', requires_grad=True),\n",
       " 'conv_L2.bias': Parameter containing:\n",
       " tensor([-1., -1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,\n",
       "          1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,\n",
       "          1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,\n",
       "          1.,  1., -1.,  1., -1., -1.], device='cuda:0', requires_grad=True),\n",
       " 'bn_L2.weight': Parameter containing:\n",
       " tensor([0.9997, 1.0003, 1.0002, 1.0010, 1.0011, 1.0003, 1.0001, 1.0002, 1.0001,\n",
       "         1.0001, 1.0006, 1.0004, 0.9999, 1.0000, 0.9993, 1.0001, 1.0006, 1.0004,\n",
       "         1.0000, 1.0006, 1.0007, 1.0003, 1.0000, 0.9997, 1.0009, 1.0000, 0.9999,\n",
       "         1.0007, 1.0005, 1.0006, 0.9998, 1.0003, 0.9997, 1.0001, 1.0001, 1.0008,\n",
       "         1.0005, 1.0001, 1.0006, 1.0003, 1.0000, 0.9997, 1.0004, 1.0000, 1.0011,\n",
       "         1.0007, 0.9998, 0.9998], device='cuda:0', requires_grad=True),\n",
       " 'bn_L2.bias': Parameter containing:\n",
       " tensor([ 2.0128e-05, -3.0414e-04,  6.8920e-04, -7.7630e-05, -4.3219e-04,\n",
       "          3.4188e-04, -3.2716e-04,  2.5710e-04, -1.8997e-04, -6.3405e-04,\n",
       "          1.2010e-04, -1.1928e-04, -5.0503e-06,  6.5913e-06, -3.9871e-04,\n",
       "         -5.4107e-04, -3.1174e-04,  6.7069e-05, -1.7987e-04, -8.6418e-05,\n",
       "          2.6717e-04, -6.8732e-04,  1.9710e-04,  1.9662e-05, -5.2774e-04,\n",
       "          1.9444e-04,  9.9901e-05, -3.6938e-04,  5.0083e-04, -4.6137e-04,\n",
       "         -6.0773e-05, -2.7747e-04, -6.0988e-05, -3.7472e-04, -2.5725e-04,\n",
       "          1.9614e-05, -1.8922e-04, -8.2517e-04, -2.5303e-04, -4.4512e-05,\n",
       "         -8.6297e-05, -4.6211e-04,  3.5678e-04,  5.9734e-04,  1.4408e-04,\n",
       "         -3.9993e-04,  2.0100e-04, -2.5932e-04], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'fc1.weight': Parameter containing:\n",
       " tensor([[-1., -1.,  1.,  ..., -1.,  1., -1.],\n",
       "         [-1.,  1., -1.,  ..., -1., -1.,  1.],\n",
       "         [ 1.,  1., -1.,  ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [ 1.,  1., -1.,  ...,  1.,  1., -1.],\n",
       "         [-1.,  1., -1.,  ..., -1., -1.,  1.],\n",
       "         [-1., -1.,  1.,  ..., -1.,  1.,  1.]], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'fc1.bias': Parameter containing:\n",
       " tensor([-1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,\n",
       "         -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "         -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "          1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,\n",
       "          1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "         -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,\n",
       "         -1., -1.], device='cuda:0', requires_grad=True),\n",
       " 'human.weight': Parameter containing:\n",
       " tensor([[ 1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,\n",
       "          -1.,  1.,  1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.,\n",
       "          -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
       "          -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,\n",
       "          -1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.,\n",
       "          -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,\n",
       "          -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "           1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "           1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,\n",
       "           1.,  1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "          -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.,\n",
       "           1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "          -1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "           1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,\n",
       "           1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "          -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "          -1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.,\n",
       "           1., -1.],\n",
       "         [ 1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "           1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
       "          -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,\n",
       "          -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.,\n",
       "           1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "           1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "           1., -1.],\n",
       "         [ 1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,\n",
       "           1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "           1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "          -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1., -1., -1.,\n",
       "          -1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,\n",
       "          -1., -1., -1.,  1., -1.,  1.,  1.,  1., -1., -1., -1., -1.,  1., -1.,\n",
       "           1.,  1., -1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,\n",
       "          -1.,  1., -1.,  1.,  1.,  1., -1., -1., -1., -1.,  1., -1.,  1., -1.,\n",
       "          -1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,\n",
       "          -1.,  1.]], device='cuda:0', requires_grad=True),\n",
       " 'human.bias': Parameter containing:\n",
       " tensor([-1.,  1.,  1.,  1.], device='cuda:0', requires_grad=True)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d6ff7ed2e65d333484b655795d870748eda876c6333e127a822707e48c97f40"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
