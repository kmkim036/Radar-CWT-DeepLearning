{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as tr\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from pytorchtools import EarlyStopping\n",
    "#from pytorchtools import EarlyStopping_acc\n",
    "from torchsummary import summary as summary_\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Function\n",
    "from binarized_modules import  BinarizeLinear,BinarizeConv2d\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(a, bit=7):\n",
    "    quant = a*(2**bit)\n",
    "    quant = quant.round()\n",
    "    quant /= 2**bit\n",
    "    return quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(motion):\n",
    "    DirectoryPath = 'C:/Users/hojung/Documents/Anaconda_python/data/class12/'\n",
    "    count = 400\n",
    "    image = np.zeros(shape=(count, rows, cols, 1))\n",
    "    label = []\n",
    "    date = '220132'\n",
    "    file_name = '_stft.txt'\n",
    "    for person in range(1, 5):\n",
    "        cwt_data = pd.read_csv(\n",
    "            DirectoryPath + date + \"_\" + str(person) + \"_\" + str(motion) + file_name)\n",
    "        for i in range(0, 100):\n",
    "            df = np.fromstring(cwt_data['pixels'][i], dtype=int, sep=' ')\n",
    "            df = np.reshape(df, (rows, cols, 1))\n",
    "            image[i + 100*(person-1)] = df\n",
    "            if motion == 0:\n",
    "                label.append(motion)\n",
    "            else:\n",
    "                label.append(motion-1)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "\n",
    "# 시작과 끝 좌표는 scale한 후의 좌표를 기준으로 함\n",
    "def preprocessing_resize_crop(image,start_row,end_row,start_col,end_col,row_scale,col_scale): \n",
    "    crop_image = image[:,0:image.shape[1]:row_scale,0:image.shape[2]:col_scale]\n",
    "    crop_image = crop_image[:,start_row:end_row,start_col:end_col]\n",
    "    return crop_image\n",
    "\n",
    "def concatenate_n_div(image0, label0, image1, label1, image2, label2): # ratio비율로 각 data set을 합치고 순서도 섞음\n",
    "    \n",
    "\n",
    "    count = 400\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    test_ratio = 0.15 # 적용안됨\n",
    "    \n",
    "    x_train = np.concatenate(\n",
    "        (image0[0:int(count*train_ratio)], image1[0:int(count*train_ratio)], image2[0:int(count*train_ratio)]))\n",
    "    y_train = np.concatenate(\n",
    "        (label0[0:int(count*train_ratio)], label1[0:int(count*train_ratio)], label2[0:int(count*train_ratio)]))\n",
    "    x_val = np.concatenate((image0[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
    "                            image1[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
    "                            image2[int(count*train_ratio):int(count*train_ratio + count*val_ratio)]))\n",
    "    y_val = np.concatenate((label0[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
    "                            label1[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
    "                            label2[int(count*train_ratio):int(count*train_ratio + count*val_ratio)]))\n",
    "    x_test = np.concatenate((image0[int(count*train_ratio + count*val_ratio): count],\n",
    "                             image1[int(count*train_ratio + count*val_ratio): count],\n",
    "                             image2[int(count*train_ratio + count*val_ratio): count]))\n",
    "    y_test = np.concatenate((label0[int(count*train_ratio + count*val_ratio): count],\n",
    "                             label1[int(count*train_ratio + count*val_ratio): count],\n",
    "                             label2[int(count*train_ratio + count*val_ratio): count]))\n",
    "    \n",
    "    s = np.arange(x_train.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    x_train = x_train[s]\n",
    "    y_train = y_train[s]\n",
    "\n",
    "    s = np.arange(x_val.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    x_val = x_val[s]\n",
    "    y_val = y_val[s]\n",
    "\n",
    "    s = np.arange(x_test.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    x_test = x_test[s]\n",
    "    y_test = y_test[s]\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "class TensorData(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.x_data = self.x_data.permute(0,3,1,2) # 이미지 개수, 채널 수, 이미지 너비, 높이\n",
    "        self.y_data = torch.LongTensor(y_data)\n",
    "        self.len = self.y_data.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(Net,self).__init__()\n",
    "        self.infl_ratio=3;\n",
    "        self.channel = 16;\n",
    "        self.features = nn.Sequential(\n",
    "            # BinarizeConv2d(입력 채널수, 출력 채널수, 커널 사이즈, 스트라이드, 패딩)\n",
    "            BinarizeConv2d(1, self.channel*self.infl_ratio,kernel_size=3,stride=1,padding=0),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1),\n",
    "            # nn.BatchNorm2d(입출력 채널수)\n",
    "            nn.BatchNorm2d(self.channel*self.infl_ratio),\n",
    "            nn.Hardtanh(),\n",
    "\n",
    "            BinarizeConv2d(self.channel*self.infl_ratio, self.channel*self.infl_ratio,kernel_size=3,stride=1,padding=0),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(self.channel*self.infl_ratio),\n",
    "            nn.Hardtanh(),\n",
    "\n",
    "            BinarizeConv2d(self.channel*self.infl_ratio, self.channel*self.infl_ratio,kernel_size=3,stride=1,padding=0),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(self.channel*self.infl_ratio),\n",
    "            nn.Hardtanh(),\n",
    "\n",
    "            BinarizeConv2d(self.channel*self.infl_ratio, self.channel,kernel_size=3,stride=1,padding=0),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(self.channel),\n",
    "            nn.Hardtanh()\n",
    "\n",
    "         )\n",
    "            \n",
    "        self.classifier = nn.Sequential(\n",
    "            # BinarizeLinear(입력 dense길이, 출력 dense길이)\n",
    "            BinarizeLinear(self.channel*20*12,32),\n",
    "            BinarizeLinear(32,num_classes)\n",
    "        )\n",
    "        self.softmax = nn.Softmax()\n",
    "                \n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1,self.channel*20*12)\n",
    "        x = self.classifier(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(Net2,self).__init__()\n",
    "        self.infl_ratio=3;\n",
    "        \n",
    "            # BinarizeConv2d(입력 채널수, 출력 채널수, 커널 사이즈, 스트라이드, 패딩)\n",
    "        self.conv_L1 = BinarizeConv2d(1, 16*self.infl_ratio,kernel_size=3,stride=1,padding='same')\n",
    "        self.max_L1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_L1 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_L1 = nn.Hardtanh()\n",
    "        self.conv_R1 = BinarizeConv2d(1, 16*self.infl_ratio,kernel_size=5,stride=1,padding='same')\n",
    "        self.max_R1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_R1 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_R1 = nn.Hardtanh()\n",
    "\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "\n",
    "        self.conv_L2 = BinarizeConv2d(16*self.infl_ratio, 16*self.infl_ratio,kernel_size=3,stride=1,padding='same')\n",
    "        self.max_L2 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_L2 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_L2 = nn.Hardtanh()\n",
    "        self.conv_R2 = BinarizeConv2d(16*self.infl_ratio, 16*self.infl_ratio,kernel_size=5,stride=1,padding='same')\n",
    "        self.max_R2 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_R2 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_R2 = nn.Hardtanh()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc1 = BinarizeLinear(48*33*25,64)\n",
    "        self.human = BinarizeLinear(64,4)\n",
    "         \n",
    "            \n",
    "        \n",
    "        self.softmax2 = nn.Softmax()\n",
    "                \n",
    "                \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_L1(x)\n",
    "        x1 = self.max_L1(x1)\n",
    "        x1 = self.bn_L1(x1)\n",
    "        x1 = self.htan_L1(x1)\n",
    "\n",
    "        x2 = self.conv_R1(x)\n",
    "        x2 = self.max_R1(x2)\n",
    "        x2 = self.bn_R1(x2)\n",
    "        x2 = self.htan_R1(x2)\n",
    "\n",
    "        x3 = torch.add(x1,x2)\n",
    "        x3 = self.max1(x3)\n",
    "\n",
    "        x4 = self.conv_L2(x3)\n",
    "        x4 = self.max_L2(x4)\n",
    "        x4 = self.bn_L2(x4)\n",
    "        x4 = self.htan_L2(x4)\n",
    "\n",
    "        x5 = self.conv_R2(x3)\n",
    "        x5 = self.max_R2(x5)\n",
    "        x5 = self.bn_R2(x5)\n",
    "        x5 = self.htan_R2(x5)\n",
    "\n",
    "        x6 = torch.add(x4,x5)\n",
    "\n",
    "        x6 = x6.view(-1,48*33*25)\n",
    "        x6 = self.fc1(x6)\n",
    "        human = self.softmax2(self.human(x6))\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        return human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net3(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(Net3,self).__init__()\n",
    "        self.infl_ratio=3;\n",
    "        \n",
    "            # BinarizeConv2d(입력 채널수, 출력 채널수, 커널 사이즈, 스트라이드, 패딩)\n",
    "        self.conv_L1 = BinarizeConv2d(1, 16*self.infl_ratio,kernel_size=3,stride=1,padding=0)\n",
    "        self.max_L1 = nn.MaxPool2d(kernel_size=3, stride=1)\n",
    "        self.bn_L1 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_L1 = nn.Hardtanh()\n",
    "        # self.conv_R1 = BinarizeConv2d(1, 16*self.infl_ratio,kernel_size=5,stride=1,padding='same')\n",
    "        # self.max_R1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        # self.bn_R1 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        # self.htan_R1 = nn.Hardtanh()\n",
    "\n",
    "        # self.max1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "\n",
    "        self.conv_L2 = BinarizeConv2d(16*self.infl_ratio, 16*self.infl_ratio,kernel_size=3,stride=1,padding=0)\n",
    "        self.max_L2 = nn.MaxPool2d(kernel_size=3, stride=1)\n",
    "        self.bn_L2 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_L2 = nn.Hardtanh()\n",
    "        # self.conv_R2 = BinarizeConv2d(16*self.infl_ratio, 16*self.infl_ratio,kernel_size=5,stride=1,padding='same')\n",
    "        # self.max_R2 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        # self.bn_R2 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        # self.htan_R2 = nn.Hardtanh()\n",
    "        \n",
    "        \n",
    "        self.fc1 = BinarizeLinear(48*28*20,128)\n",
    "        self.human = BinarizeLinear(128,3)\n",
    "         \n",
    "            \n",
    "        \n",
    "        self.softmax2 = nn.Softmax()\n",
    "                \n",
    "                \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_L1(x)\n",
    "        x1 = self.max_L1(x1)\n",
    "        x1 = self.bn_L1(x1)\n",
    "        x1 = self.htan_L1(x1)\n",
    "        \n",
    "        # x2 = self.conv_R1(x)\n",
    "        # x2 = self.max_R1(x2)\n",
    "        # x2 = self.bn_R1(x2)\n",
    "        # x2 = self.htan_R1(x2)\n",
    "\n",
    "        # x3 = torch.add(x1,x2)\n",
    "        # x3 = self.max1(x3)\n",
    "\n",
    "        x1 = self.conv_L2(x1)\n",
    "        x1 = self.max_L2(x1)\n",
    "        x1 = self.bn_L2(x1)\n",
    "        x1 = self.htan_L2(x1)\n",
    "        \n",
    "        # x5 = self.conv_R2(x3)\n",
    "        # x5 = self.max_R2(x5)\n",
    "        # x5 = self.bn_R2(x5)\n",
    "        # x5 = self.htan_R2(x5)\n",
    "\n",
    "        \n",
    "\n",
    "        x1 = x1.view(-1,48*28*20)\n",
    "        x1 = self.fc1(x1)\n",
    "        human = self.softmax2(self.human(x1))\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        return human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(Net2,self).__init__()\n",
    "        self.infl_ratio=3;\n",
    "        \n",
    "            # BinarizeConv2d(입력 채널수, 출력 채널수, 커널 사이즈, 스트라이드, 패딩)\n",
    "        self.conv_L1 = BinarizeConv2d(1, 16*self.infl_ratio,kernel_size=3,stride=1,padding='same')\n",
    "        self.max_L1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_L1 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_L1 = nn.Hardtanh()\n",
    "        self.conv_R1 = BinarizeConv2d(1, 16*self.infl_ratio,kernel_size=5,stride=1,padding='same')\n",
    "        self.max_R1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_R1 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_R1 = nn.Hardtanh()\n",
    "\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "\n",
    "        self.conv_L2 = BinarizeConv2d(16*self.infl_ratio, 16*self.infl_ratio,kernel_size=3,stride=1,padding='same')\n",
    "        self.max_L2 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_L2 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_L2 = nn.Hardtanh()\n",
    "        self.conv_R2 = BinarizeConv2d(16*self.infl_ratio, 16*self.infl_ratio,kernel_size=5,stride=1,padding='same')\n",
    "        self.max_R2 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_R2 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_R2 = nn.Hardtanh()\n",
    "        \n",
    "        self.max2 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "\n",
    "        self.conv_L3 = BinarizeConv2d(16*self.infl_ratio, 16*self.infl_ratio,kernel_size=3,stride=1,padding='same')\n",
    "        self.max_L3 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_L3 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_L3 = nn.Hardtanh()\n",
    "        self.conv_R3 = BinarizeConv2d(16*self.infl_ratio, 16*self.infl_ratio,kernel_size=5,stride=1,padding='same')\n",
    "        self.max_R3 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.bn_R3 = nn.BatchNorm2d(16*self.infl_ratio) # nn.BatchNorm2d(입출력 채널수)\n",
    "        self.htan_R3 = nn.Hardtanh()\n",
    "        \n",
    "        self.max3 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        \n",
    "        self.fc1 = BinarizeLinear(48*30*22,128)\n",
    "        self.human = BinarizeLinear(128,4)\n",
    "        #self.motion = BinarizeLinear(128,3)\n",
    "            \n",
    "        self.softmax1 = nn.Softmax()\n",
    "        self.softmax2 = nn.Softmax()\n",
    "                \n",
    "                \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_L1(x)\n",
    "        x1 = self.max_L1(x1)\n",
    "        x1 = self.bn_L1(x1)\n",
    "        x1 = self.htan_L1(x1)\n",
    "\n",
    "        x2 = self.conv_R1(x)\n",
    "        x2 = self.max_R1(x2)\n",
    "        x2 = self.bn_R1(x2)\n",
    "        x2 = self.htan_R1(x2)\n",
    "\n",
    "        x3 = torch.add(x1,x2)\n",
    "        x3 = self.max1(x3)\n",
    "\n",
    "        x4 = self.conv_L2(x3)\n",
    "        x4 = self.max_L2(x4)\n",
    "        x4 = self.bn_L2(x4)\n",
    "        x4 = self.htan_L2(x4)\n",
    "\n",
    "        x5 = self.conv_R2(x3)\n",
    "        x5 = self.max_R2(x5)\n",
    "        x5 = self.bn_R2(x5)\n",
    "        x5 = self.htan_R2(x5)\n",
    "\n",
    "        x6 = torch.add(x4,x5)\n",
    "        x6 = self.max2(x6)\n",
    "        \n",
    "        x7 = self.conv_L3(x6)\n",
    "        x7 = self.max_L3(x7)\n",
    "        x7 = self.bn_L3(x7)\n",
    "        x7 = self.htan_L3(x7)\n",
    "\n",
    "        x8 = self.conv_R3(x6)\n",
    "        x8 = self.max_R3(x8)\n",
    "        x8 = self.bn_R3(x8)\n",
    "        x8 = self.htan_R3(x8)\n",
    "\n",
    "        x9 = torch.add(x7,x8)\n",
    "        x9 = self.max3(x9)\n",
    "        \n",
    "        x9 = x9.view(-1,48*30*22)\n",
    "        x9 = self.fc1(x9)\n",
    "        human = self.softmax2(self.human(x9))\n",
    "        #motion = self.softmax1(self.motion(x9))\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        return human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "    BinarizeConv2d-1           [32, 48, 34, 26]             480\n",
      "         MaxPool2d-2           [32, 48, 32, 24]               0\n",
      "       BatchNorm2d-3           [32, 48, 32, 24]              96\n",
      "          Hardtanh-4           [32, 48, 32, 24]               0\n",
      "    BinarizeConv2d-5           [32, 48, 30, 22]          20,784\n",
      "         MaxPool2d-6           [32, 48, 28, 20]               0\n",
      "       BatchNorm2d-7           [32, 48, 28, 20]              96\n",
      "          Hardtanh-8           [32, 48, 28, 20]               0\n",
      "    BinarizeLinear-9                  [32, 128]       3,440,768\n",
      "   BinarizeLinear-10                    [32, 3]             387\n",
      "          Softmax-11                    [32, 3]               0\n",
      "================================================================\n",
      "Total params: 3,462,611\n",
      "Trainable params: 3,462,611\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 64.81\n",
      "Params size (MB): 13.21\n",
      "Estimated Total Size (MB): 78.15\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_23028/1215408488.py:65: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  human = self.softmax2(self.human(x1))\n"
     ]
    }
   ],
   "source": [
    "net = Net3().to(device)\n",
    "summary_(net,(1,36,28),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device), \n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for p in list(model.parameters()):\n",
    "            if hasattr(p,'org'):\n",
    "                p.data.copy_(p.org)\n",
    "        optimizer.step()\n",
    "        for p in list(model.parameters()):\n",
    "            if hasattr(p,'org'):\n",
    "                p.org.copy_(p.data.clamp_(-1,1))\n",
    "                \n",
    "        if batch % 40 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred,y)\n",
    "            test_loss += loss.item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy_human: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    return 100*correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALE:16 /1초 추출 + 0.2초 씩 이동 / row 30\n",
    "#=========================================================\n",
    "#================파라미터 설정==========================\n",
    "#============================================================\n",
    "# STFT = (128, 29) //  CWT = (81,1920)\n",
    "# 좌표는 스케일 이후 범위\n",
    "start_row = 46\n",
    "end_row = 82\n",
    "scale_row = 1\n",
    "rows = 128\n",
    "\n",
    "start_col = 0\n",
    "end_col = 28\n",
    "scale_col = 1\n",
    "cols = 29\n",
    "\n",
    "aug = 1  # 1이면 augmentation 0이면 X\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "                         width_shift_range=0.2\n",
    "                            )\n",
    "\n",
    "\n",
    "image1, label1 = preprocessing(0)  # motion 0 불러옴\n",
    "image2, label2 = preprocessing(2)  # motion 2 불러옴\n",
    "image3, label3 = preprocessing(3)  # motion 3 불러옴\n",
    "\n",
    "# 정규화 추가\n",
    "total_img = np.concatenate((image1, image2, image3))\n",
    "total_std = total_img.std()\n",
    "total_mean = total_img.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total try_num 1, Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_23028/1215408488.py:65: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  human = self.softmax2(self.human(x1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.240242  [    0/ 8400]\n",
      "loss: 0.702805  [ 1280/ 8400]\n",
      "loss: 0.736577  [ 2560/ 8400]\n",
      "loss: 0.691662  [ 3840/ 8400]\n",
      "loss: 0.551446  [ 5120/ 8400]\n",
      "loss: 0.709080  [ 6400/ 8400]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_23028/3236225277.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"total try_num {a+1}, Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mhuman_result_acc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_23028/1308190735.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# Compute prediction error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "epochs = 10  # 학습을 원하는 만큼 수정요\n",
    "try_num = 5\n",
    "human_result_acc = np.zeros(try_num*2*epochs).reshape(try_num,2,epochs)\n",
    "motion_result_acc = np.zeros(try_num*2*epochs).reshape(try_num,2,epochs)\n",
    "average_result_acc = np.zeros(try_num*epochs).reshape(try_num,epochs)\n",
    "average_acc = 0\n",
    "quanta = 1\n",
    "start = datetime.datetime.now()\n",
    "for a in range(try_num):\n",
    "\n",
    "    model = Net3()\n",
    "    model.cuda()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "    \n",
    "    s = np.arange(image1.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    image1_shuff = image1[s]       # 불러온 성진_motion data의 순서를 섞음\n",
    "\n",
    "    s = np.arange(image2.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    image2_shuff = image2[s]       # 불러온 호정_motion data의 순서를 섞음\n",
    "\n",
    "    s = np.arange(image3.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    image3_shuff = image3[s]       # 불러온 3_motion data의 순서를 섞음\n",
    "\n",
    "   \n",
    "\n",
    "    image1_crop = preprocessing_resize_crop(\n",
    "        image1_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
    "    image2_crop = preprocessing_resize_crop(\n",
    "        image2_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
    "    image3_crop = preprocessing_resize_crop(\n",
    "        image3_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
    "\n",
    "\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = concatenate_n_div(\n",
    "            image1_crop, label1, image2_crop, label2, image3_crop, label3)\n",
    "                # 자른 image를 각 data set으로 나눠서 합침\n",
    "\n",
    "    x_train = (x_train - total_mean) / total_std\n",
    "    x_val = (x_val - total_mean) / total_std\n",
    "    x_test = (x_test - total_mean) / total_std\n",
    "\n",
    "    # 보강할 학습데이터 이미지 생성\n",
    "    if aug == 1:\n",
    "        augment_ratio = 9   # 전체 데이터의 150%\n",
    "        augment_size = int(augment_ratio * x_train.shape[0])\n",
    "\n",
    "        # 전체 x_train 개수의 150% 비율만큼\n",
    "        randidx = np.random.randint(x_train.shape[0], size=augment_size)\n",
    "\n",
    "        # 임의로 선택된 데이터는 원본데이터를 참조하기 때문에\n",
    "        # 원본데이터에 영향을 줄수 있음. 그래서 copy() 함수를 통해 안전하게 복사본 만듬\n",
    "        x_augmented = x_train[randidx].copy()  \n",
    "        y_augmented = y_train[randidx].copy()\n",
    "\n",
    "        #  이미지 보강 실행\n",
    "        x_augmented, y_augmented = gen.flow(x_augmented, y_augmented, \n",
    "                                            batch_size=augment_size,\n",
    "                                            shuffle=False).next()\n",
    "\n",
    "        x_train = np.concatenate((x_train,x_augmented))\n",
    "        y_train = np.concatenate((y_train,y_augmented))\n",
    "        s = np.arange(x_train.shape[0])\n",
    "        np.random.shuffle(s)\n",
    "        x_train = x_train[s]\n",
    "        y_train = y_train[s]\n",
    "\n",
    "    if quanta == 1:\n",
    "        x_train = quantize(x_train)\n",
    "        x_val = quantize(x_val)\n",
    "        x_test = quantize(x_test)\n",
    "\n",
    "    train_data = TensorData(x_train,y_train)\n",
    "    test_data = TensorData(x_test,y_test)\n",
    "    valid_data = TensorData(x_val,y_val)\n",
    "    train_loader = DataLoader(train_data, batch_size = 32, shuffle =True)\n",
    "    test_loader = DataLoader(test_data, batch_size = 32, shuffle =True)\n",
    "    valid_loader = DataLoader(valid_data, batch_size = 32, shuffle =True)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"total try_num {a+1}, Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_loader, model, criterion, optimizer)\n",
    "\n",
    "        human_result_acc[a][0][t] = test(valid_loader, model, criterion)\n",
    "        human_result_acc[a][1][t] = test(test_loader, model, criterion)\n",
    "        average_result_acc[a][t] = (human_result_acc[a][0][t] + human_result_acc[a][1][t]) / 2\n",
    "print(\"Done!\")\n",
    "end = datetime.datetime.now()\n",
    "print('동작시간 :', end - start)\n",
    "for b in range(try_num):\n",
    "    print(f\"try : {b+1} // epoch : {np.argmax(average_result_acc[b])+1} // Max_average_accuracy = {max(average_result_acc[b]):0.1f},\\\n",
    " Max_accuray_valid_human = {human_result_acc[b][0][np.argmax(average_result_acc[b])]:0.1f},\\\n",
    " Max_accuray_test_human = {human_result_acc[b][1][np.argmax(average_result_acc[b])]:0.1f}\\n \")\n",
    "    average_acc += max(average_result_acc[b])\n",
    "average_acc /= try_num\n",
    "print(f\"total average_acc = {average_acc:0.1f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동작시간 : 0:01:24.752994\n",
      "try : 1 // epoch : 4 // Max_average_accuracy = 98.9, Max_accuray_valid_human = 98.9, Max_accuray_test_human = 98.9\n",
      " \n",
      "try : 2 // epoch : 10 // Max_average_accuracy = 98.3, Max_accuray_valid_human = 98.3, Max_accuray_test_human = 98.3\n",
      " \n",
      "try : 3 // epoch : 10 // Max_average_accuracy = 99.2, Max_accuray_valid_human = 98.9, Max_accuray_test_human = 99.4\n",
      " \n",
      "try : 4 // epoch : 4 // Max_average_accuracy = 98.6, Max_accuray_valid_human = 97.8, Max_accuray_test_human = 99.4\n",
      " \n",
      "try : 5 // epoch : 10 // Max_average_accuracy = 97.8, Max_accuray_valid_human = 97.8, Max_accuray_test_human = 97.8\n",
      " \n",
      "total average_acc = 98.6\n"
     ]
    }
   ],
   "source": [
    "print('동작시간 :', end - start)\n",
    "for b in range(try_num):\n",
    "    print(f\"try : {b+1} // epoch : {np.argmax(average_result_acc[b])+1} // Max_average_accuracy = {max(average_result_acc[b]):0.1f},\\\n",
    " Max_accuray_valid_human = {human_result_acc[b][0][np.argmax(average_result_acc[b])]:0.1f},\\\n",
    " Max_accuray_test_human = {human_result_acc[b][1][np.argmax(average_result_acc[b])]:0.1f}\\n \")\n",
    "\n",
    "print(f\"total average_acc = {average_acc:0.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_L1.weight': Parameter containing:\n",
       " tensor([[[[-1., -1.,  1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [ 1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1.,  1.],\n",
       "           [-1., -1., -1.],\n",
       "           [ 1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1., -1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [ 1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1., -1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [ 1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [-1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [-1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1.,  1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [ 1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1.,  1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [ 1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1.,  1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [ 1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1.,  1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [-1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [-1., -1., -1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [-1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1.,  1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [ 1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1., -1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [-1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1.,  1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1.,  1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [ 1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.],\n",
       "           [-1., -1., -1.],\n",
       "           [-1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1., -1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [-1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1., -1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [ 1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [-1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1.,  1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [ 1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [-1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1., -1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [ 1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1.,  1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [ 1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [-1., -1., -1.],\n",
       "           [-1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1., -1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [-1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.],\n",
       "           [-1., -1., -1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1., -1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [-1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1., -1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1., -1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1., -1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [-1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1., -1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [-1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1.,  1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [-1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1., -1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [-1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1.,  1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [ 1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1., -1.,  1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1.,  1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [ 1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1., -1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1.,  1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [ 1., -1.,  1.]]]], device='cuda:0', requires_grad=True),\n",
       " 'conv_L1.bias': Parameter containing:\n",
       " tensor([-1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "          1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n",
       "          1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
       "         -1., -1., -1.,  1.,  1.,  1.], device='cuda:0', requires_grad=True),\n",
       " 'bn_L1.weight': Parameter containing:\n",
       " tensor([0.9997, 1.0001, 1.0003, 0.9999, 1.0001, 0.9997, 0.9996, 0.9997, 0.9996,\n",
       "         1.0002, 1.0006, 0.9999, 1.0002, 0.9998, 0.9993, 1.0006, 0.9999, 1.0001,\n",
       "         0.9995, 1.0001, 0.9999, 0.9990, 0.9997, 0.9998, 1.0001, 0.9995, 0.9999,\n",
       "         1.0000, 1.0008, 0.9989, 1.0006, 0.9997, 0.9998, 1.0000, 0.9999, 1.0001,\n",
       "         0.9999, 0.9993, 1.0005, 1.0003, 1.0000, 1.0000, 1.0001, 0.9996, 1.0001,\n",
       "         1.0000, 1.0002, 1.0002], device='cuda:0', requires_grad=True),\n",
       " 'bn_L1.bias': Parameter containing:\n",
       " tensor([-9.0341e-05, -1.6165e-04, -6.8746e-04,  2.5402e-04, -2.4176e-04,\n",
       "         -6.6273e-04, -7.6793e-04,  3.0548e-04,  2.3107e-04,  6.2512e-04,\n",
       "          5.7420e-04, -6.1098e-04, -5.7662e-04,  1.6489e-04,  2.2794e-04,\n",
       "         -5.1922e-04, -7.3788e-04, -7.0028e-04,  3.0732e-04, -1.7449e-04,\n",
       "         -4.4084e-04, -7.3095e-05, -9.2732e-05,  2.8677e-04,  7.0257e-04,\n",
       "          3.1123e-05, -3.5978e-04,  2.8595e-04, -1.8248e-04, -6.1177e-04,\n",
       "         -8.3060e-06, -4.6219e-04, -6.2340e-04, -4.2665e-04, -1.7856e-04,\n",
       "         -5.0778e-04, -3.8511e-04, -4.1977e-04, -4.1274e-04,  4.3694e-04,\n",
       "          1.1664e-04, -6.9500e-05, -6.3255e-04,  1.4616e-04, -6.4813e-04,\n",
       "         -1.3806e-03, -2.5797e-04, -2.4921e-04], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'conv_L2.weight': Parameter containing:\n",
       " tensor([[[[ 1.,  1., -1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [ 1., -1.,  1.]],\n",
       " \n",
       "          [[-1.,  1., -1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [ 1.,  1.,  1.]],\n",
       " \n",
       "          [[ 1.,  1.,  1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [ 1., -1.,  1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1., -1.,  1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.]],\n",
       " \n",
       "          [[ 1., -1., -1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.]],\n",
       " \n",
       "          [[ 1.,  1.,  1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [ 1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [-1., -1.,  1.]],\n",
       " \n",
       "          [[-1., -1.,  1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [-1., -1., -1.]],\n",
       " \n",
       "          [[ 1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [ 1.,  1., -1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1., -1., -1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [-1., -1.,  1.]],\n",
       " \n",
       "          [[-1.,  1., -1.],\n",
       "           [-1., -1., -1.],\n",
       "           [-1.,  1., -1.]],\n",
       " \n",
       "          [[ 1.,  1.,  1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [-1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[ 1.,  1., -1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.]],\n",
       " \n",
       "          [[-1., -1.,  1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [ 1.,  1., -1.]],\n",
       " \n",
       "          [[-1.,  1., -1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [ 1.,  1., -1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.,  1.,  1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [ 1.,  1., -1.]],\n",
       " \n",
       "          [[-1.,  1., -1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [ 1.,  1., -1.]],\n",
       " \n",
       "          [[ 1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [ 1.,  1., -1.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.],\n",
       "           [-1., -1., -1.],\n",
       "           [ 1., -1.,  1.]],\n",
       " \n",
       "          [[ 1., -1.,  1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [ 1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [ 1., -1., -1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1., -1.,  1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [-1.,  1., -1.]],\n",
       " \n",
       "          [[ 1.,  1.,  1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [-1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [ 1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [-1., -1.,  1.]],\n",
       " \n",
       "          [[-1.,  1.,  1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [-1., -1., -1.]],\n",
       " \n",
       "          [[-1.,  1.,  1.],\n",
       "           [-1.,  1.,  1.],\n",
       "           [ 1.,  1.,  1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1., -1., -1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [-1., -1.,  1.]],\n",
       " \n",
       "          [[ 1.,  1., -1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [-1., -1., -1.]],\n",
       " \n",
       "          [[ 1., -1.,  1.],\n",
       "           [ 1.,  1., -1.],\n",
       "           [ 1., -1.,  1.]]],\n",
       " \n",
       " \n",
       "         [[[-1.,  1., -1.],\n",
       "           [-1., -1., -1.],\n",
       "           [-1.,  1.,  1.]],\n",
       " \n",
       "          [[ 1.,  1.,  1.],\n",
       "           [-1.,  1., -1.],\n",
       "           [ 1., -1., -1.]],\n",
       " \n",
       "          [[ 1.,  1.,  1.],\n",
       "           [-1., -1.,  1.],\n",
       "           [ 1.,  1.,  1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.,  1.,  1.],\n",
       "           [ 1., -1., -1.],\n",
       "           [ 1., -1., -1.]],\n",
       " \n",
       "          [[ 1., -1.,  1.],\n",
       "           [ 1.,  1.,  1.],\n",
       "           [-1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1.,  1.],\n",
       "           [ 1., -1.,  1.],\n",
       "           [-1.,  1., -1.]]]], device='cuda:0', requires_grad=True),\n",
       " 'conv_L2.bias': Parameter containing:\n",
       " tensor([ 1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,\n",
       "         -1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "         -1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,\n",
       "         -1.,  1., -1., -1., -1., -1.], device='cuda:0', requires_grad=True),\n",
       " 'bn_L2.weight': Parameter containing:\n",
       " tensor([1.0002, 1.0012, 1.0000, 1.0006, 1.0003, 1.0004, 1.0006, 1.0004, 1.0006,\n",
       "         1.0001, 0.9999, 1.0015, 1.0011, 1.0001, 1.0003, 0.9998, 1.0005, 1.0004,\n",
       "         1.0009, 1.0001, 1.0005, 0.9995, 0.9995, 1.0007, 0.9999, 1.0013, 1.0011,\n",
       "         1.0005, 1.0013, 1.0007, 0.9999, 1.0010, 1.0010, 0.9998, 1.0004, 1.0002,\n",
       "         1.0002, 1.0008, 1.0001, 1.0003, 1.0009, 1.0003, 0.9998, 1.0002, 1.0007,\n",
       "         1.0005, 1.0007, 1.0008], device='cuda:0', requires_grad=True),\n",
       " 'bn_L2.bias': Parameter containing:\n",
       " tensor([-2.7913e-04, -2.6670e-04, -3.5180e-04, -9.2429e-05, -9.7727e-05,\n",
       "         -3.5279e-04,  2.9386e-04,  9.5722e-06, -1.2400e-04, -1.0738e-04,\n",
       "         -1.4994e-04, -6.6779e-04, -1.7531e-04, -2.1086e-04, -7.6275e-04,\n",
       "         -3.4980e-04, -1.0059e-04, -3.3681e-04, -3.0666e-04, -1.1048e-04,\n",
       "          1.9348e-04, -4.0695e-04, -3.5493e-04, -4.9389e-04,  3.9511e-04,\n",
       "         -3.8435e-04,  1.6384e-04,  3.7879e-04, -1.2048e-05,  1.5202e-04,\n",
       "          2.3208e-04, -4.0918e-04, -1.9402e-04,  6.2975e-04, -1.2759e-04,\n",
       "         -5.0406e-04, -1.7837e-04, -9.2711e-05, -1.9666e-04, -4.8962e-04,\n",
       "          4.0284e-04, -2.9628e-04, -3.5413e-04,  3.0788e-04,  3.8675e-06,\n",
       "          2.2530e-04, -2.7159e-04, -1.0132e-04], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'fc1.weight': Parameter containing:\n",
       " tensor([[-1., -1.,  1.,  ...,  1., -1., -1.],\n",
       "         [-1.,  1., -1.,  ...,  1., -1., -1.],\n",
       "         [-1.,  1.,  1.,  ...,  1.,  1., -1.],\n",
       "         ...,\n",
       "         [-1., -1.,  1.,  ...,  1., -1., -1.],\n",
       "         [ 1., -1., -1.,  ...,  1., -1.,  1.],\n",
       "         [ 1.,  1.,  1.,  ..., -1., -1.,  1.]], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'fc1.bias': Parameter containing:\n",
       " tensor([-1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,\n",
       "          1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,\n",
       "          1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1.,  1.,\n",
       "          1.,  1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1.,\n",
       "          1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "         -1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1., -1., -1.,  1.,\n",
       "          1., -1., -1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "          1., -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "         -1., -1.], device='cuda:0', requires_grad=True),\n",
       " 'human.weight': Parameter containing:\n",
       " tensor([[-1., -1.,  1., -1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1.,  1.,\n",
       "          -1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,\n",
       "          -1.,  1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,  1.,\n",
       "          -1.,  1.,  1., -1., -1.,  1., -1.,  1., -1., -1., -1.,  1., -1.,  1.,\n",
       "           1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,\n",
       "          -1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1., -1.,  1., -1.,  1.,\n",
       "           1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,\n",
       "           1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "          -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,\n",
       "           1., -1.],\n",
       "         [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,\n",
       "           1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1., -1.,\n",
       "          -1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1.,\n",
       "          -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1.,\n",
       "          -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "           1.,  1.,  1.,  1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1.,  1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,\n",
       "          -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,\n",
       "           1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1., -1., -1., -1.,\n",
       "           1., -1.],\n",
       "         [-1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "          -1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,\n",
       "          -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,\n",
       "           1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1.,\n",
       "          -1.,  1.,  1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "          -1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1., -1., -1.,\n",
       "           1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "          -1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "          -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1., -1.,  1., -1., -1.,\n",
       "          -1., -1.],\n",
       "         [ 1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "          -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "          -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "           1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.,\n",
       "          -1., -1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,\n",
       "          -1., -1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "          -1.,  1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.,\n",
       "           1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
       "           1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1.,\n",
       "          -1.,  1.]], device='cuda:0', requires_grad=True),\n",
       " 'human.bias': Parameter containing:\n",
       " tensor([ 1.,  1., -1., -1.], device='cuda:0', requires_grad=True)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d6ff7ed2e65d333484b655795d870748eda876c6333e127a822707e48c97f40"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
