{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "MTL_FilnalTest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "최종 output으로 출력되는 사람 구분 정확도와 모션 구분 정확도를 바로 사용  \n",
        "3번째 cell의 convlayers와 denseparam 변수를 변경해보며 테스트"
      ],
      "metadata": {
        "id": "wew7NH9bt-Fo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# setting for load google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [],
      "metadata": {
        "id": "9HHiclKKt8HE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Input, Flatten, Add, BatchNormalization, Activation, Input\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns"
      ],
      "outputs": [],
      "metadata": {
        "id": "v7DeATQjt7ff"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# parameters to change\n",
        "convlayers = 2\n",
        "denseparam = 128\n",
        "\n",
        "augment_ratio = 9\n",
        "\n",
        "try_num = 10   # 같은 조건에서 몇번 반복할지\n",
        "\n",
        "date = '220132'\n",
        "\n",
        "count = 100\n",
        "\n",
        "lr = 0.001\n",
        "bs = 64\n",
        "wsr = 0.15\n",
        "\n",
        "classnum_human = 4\n",
        "classnum_motion = 3\n",
        "\n",
        "test_label_human = np.zeros(classnum_human).reshape(1, classnum_human)\n",
        "predict_label_human = np.zeros(classnum_human).reshape(1, classnum_human)\n",
        "\n",
        "test_label_motion = np.zeros(classnum_motion).reshape(1, classnum_motion)\n",
        "predict_label_motion = np.zeros(classnum_motion).reshape(1, classnum_motion)\n",
        "\n",
        "file_name = '_stft.txt'\n",
        "\n",
        "start_row = 46\n",
        "end_row = 82\n",
        "scale_row = 1\n",
        "rows = 128\n",
        "\n",
        "start_col = 1\n",
        "end_col = 29\n",
        "scale_col = 1\n",
        "cols = 29\n",
        "\n",
        "def create_CNNmodel(classnum_human, classnum_motion, lr, img_row, img_col):\n",
        "\n",
        "    model_input = Input(shape=(img_row, img_col, 1), name='main_input')\n",
        "\n",
        "    left_branch1 = Conv2D(16, kernel_size=(3, 3), strides=(1, 1), padding = 'same', activation = 'relu')(model_input)\n",
        "    left_branch1 = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(left_branch1)\n",
        "\n",
        "    right_branch1 = Conv2D(16, kernel_size=(5, 5), strides=(1, 1), padding = 'same', activation = 'relu')(model_input)\n",
        "    right_branch1 = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(right_branch1)\n",
        "\n",
        "    main_branch1 = Add()([left_branch1, right_branch1])\n",
        "    main_branch1 = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(main_branch1)\n",
        "\n",
        "    left_branch2 = Conv2D(16, kernel_size=(3, 3), strides=(1, 1), padding = 'same', activation = 'relu')(main_branch1)\n",
        "    left_branch2 = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(left_branch2)\n",
        "\n",
        "    right_branch2 = Conv2D(16, kernel_size=(5, 5), strides=(1, 1), padding = 'same', activation = 'relu')(main_branch1)\n",
        "    right_branch2 = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(right_branch2)\n",
        "\n",
        "    main_branch2 = Add()([left_branch2, right_branch2])\n",
        "    main_branch2 = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(main_branch2)\n",
        "\n",
        "    left_branch3 = Conv2D(16, kernel_size=(3, 3), strides=(1, 1), padding = 'same', activation = 'relu')(main_branch2)\n",
        "    left_branch3 = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(left_branch3)\n",
        "\n",
        "    right_branch3 = Conv2D(16, kernel_size=(5, 5), strides=(1, 1), padding = 'same', activation = 'relu')(main_branch2)\n",
        "    right_branch3 = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(right_branch3)\n",
        "\n",
        "    main_branch3 = Add()([left_branch3, right_branch3])\n",
        "    main_branch3 = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(main_branch3)\n",
        "\n",
        "    left_branch4 = Conv2D(16, kernel_size=(3, 3), strides=(1, 1), padding = 'same', activation = 'relu')(main_branch3)\n",
        "    left_branch4 = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(left_branch4)\n",
        "\n",
        "    right_branch4 = Conv2D(16, kernel_size=(5, 5), strides=(1, 1), padding = 'same', activation = 'relu')(main_branch3)\n",
        "    right_branch4 = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(right_branch4)\n",
        "\n",
        "    main_branch4 = Add()([left_branch4, right_branch4])\n",
        "    main_branch4 = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(main_branch4)\n",
        "\n",
        "    if convlayers == 1:\n",
        "      main_branch = Flatten()(main_branch1)\n",
        "    elif convlayers == 2:\n",
        "      main_branch = Flatten()(main_branch2)\n",
        "    elif convlayers == 3:\n",
        "      print(\"check\")\n",
        "      main_branch = Flatten()(main_branch3)\n",
        "    elif convlayers == 4:\n",
        "      main_branch = Flatten()(main_branch4)      \n",
        "\n",
        "    main_branch = Dense(denseparam, activation='relu')(main_branch)\n",
        "\n",
        "    human = Dense(classnum_human, activation='softmax', name = 'human_output')(main_branch)\n",
        "    motion = Dense(classnum_motion, activation='softmax', name = 'motion_output')(main_branch)\n",
        "\n",
        "    model = Model(inputs = model_input, outputs = [human, motion])\n",
        "    \n",
        "    model.compile(optimizer=Adam(lr), \n",
        "                  loss=['categorical_crossentropy', 'categorical_crossentropy'],\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def preprocessing(person, motion):  # person, motion에 해당하는 image 불러옴\n",
        "    DirectoryPath = '/content/drive/MyDrive/dataset/'\n",
        "\n",
        "    image = np.zeros(shape=(count, rows, cols, 1))\n",
        "    label1 = []\n",
        "    label2 = []\n",
        "\n",
        "    cwt_data = pd.read_csv(\n",
        "        DirectoryPath + date + \"_\" + str(person) + \"_\" + str(motion) + file_name)\n",
        "    for i in range(0, 100):\n",
        "        df = np.fromstring(cwt_data['pixels'][i], dtype=int, sep=' ')\n",
        "        df = np.reshape(df, (rows, cols, 1))\n",
        "        image[i] = df\n",
        "        label1.append(person - 1)\n",
        "        if motion == 0:\n",
        "            label2.append(motion)\n",
        "        else:\n",
        "            label2.append(motion - 1)\n",
        "\n",
        "    return image, label1, label2\n",
        "\n",
        "\n",
        "# 시작과 끝 좌표는 scale한 후의 좌표를 기준으로 함\n",
        "def preprocessing_resize_crop(image, start_row, end_row, start_col, end_col, row_scale, col_scale):\n",
        "    crop_image = image[:, 0:image.shape[1]\n",
        "        :row_scale, 0:image.shape[2]:col_scale]\n",
        "    crop_image = crop_image[:, start_row:end_row, start_col:end_col]\n",
        "    return crop_image\n",
        "\n",
        "\n",
        "# ratio비율로 각 data set을 합치고 순서도 섞음\n",
        "def concatenate_n_div(image0, label0_1, label0_2, image1, label1_1, label1_2, image2, label2_1, label2_2, image3, label3_1, label3_2, image4, label4_1, label4_2, image5, label5_1, label5_2, image6, label6_1, label6_2, image7, label7_1, label7_2, image8, label8_1, label8_2, image9, label9_1, label9_2, image10, label10_1, label10_2, image11, label11_1, label11_2):\n",
        "    train_ratio = 0.7\n",
        "    val_ratio = 0.15\n",
        "    test_ratio = 0.15  # 적용안됨\n",
        "\n",
        "    x_train = np.concatenate(\n",
        "        (image0[0:int(count*train_ratio)],\n",
        "         image1[0:int(count*train_ratio)],\n",
        "         image2[0:int(count*train_ratio)],\n",
        "         image3[0:int(count*train_ratio)],\n",
        "         image4[0:int(count*train_ratio)],\n",
        "         image5[0:int(count*train_ratio)],\n",
        "         image6[0:int(count*train_ratio)],\n",
        "         image7[0:int(count*train_ratio)],\n",
        "         image8[0:int(count*train_ratio)],\n",
        "         image9[0:int(count*train_ratio)],\n",
        "         image10[0:int(count*train_ratio)],\n",
        "         image11[0:int(count*train_ratio)]))\n",
        "    y_train_human = np.concatenate(\n",
        "        (label0_1[0:int(count*train_ratio)],\n",
        "         label1_1[0:int(count*train_ratio)],\n",
        "         label2_1[0:int(count*train_ratio)],\n",
        "         label3_1[0:int(count*train_ratio)],\n",
        "         label4_1[0:int(count*train_ratio)],\n",
        "         label5_1[0:int(count*train_ratio)],\n",
        "         label6_1[0:int(count*train_ratio)],\n",
        "         label7_1[0:int(count*train_ratio)],\n",
        "         label8_1[0:int(count*train_ratio)],\n",
        "         label9_1[0:int(count*train_ratio)],\n",
        "         label10_1[0:int(count*train_ratio)],\n",
        "         label11_1[0:int(count*train_ratio)]))\n",
        "    y_train_motion = np.concatenate(\n",
        "        (label0_2[0:int(count*train_ratio)],\n",
        "         label1_2[0:int(count*train_ratio)],\n",
        "         label2_2[0:int(count*train_ratio)],\n",
        "         label3_2[0:int(count*train_ratio)],\n",
        "         label4_2[0:int(count*train_ratio)],\n",
        "         label5_2[0:int(count*train_ratio)],\n",
        "         label6_2[0:int(count*train_ratio)],\n",
        "         label7_2[0:int(count*train_ratio)],\n",
        "         label8_2[0:int(count*train_ratio)],\n",
        "         label9_2[0:int(count*train_ratio)],\n",
        "         label10_2[0:int(count*train_ratio)],\n",
        "         label11_2[0:int(count*train_ratio)]))\n",
        "    x_val = np.concatenate((image0[int(count*train_ratio):int(count *\n",
        "                                                              train_ratio + count*val_ratio)],\n",
        "                            image1[int(count*train_ratio):int(count *\n",
        "                                                              train_ratio + count*val_ratio)],\n",
        "                            image2[int(count*train_ratio):int(count *\n",
        "                                                              train_ratio + count*val_ratio)],\n",
        "                            image3[int(count*train_ratio):int(count *\n",
        "                                                              train_ratio + count*val_ratio)],\n",
        "                            image4[int(count*train_ratio):int(count *\n",
        "                                                              train_ratio + count*val_ratio)],\n",
        "                            image5[int(count*train_ratio):int(count *\n",
        "                                                              train_ratio + count*val_ratio)],\n",
        "                            image6[int(count*train_ratio):int(count *\n",
        "                                                              train_ratio + count*val_ratio)],\n",
        "                            image7[int(count*train_ratio):int(count *\n",
        "                                                              train_ratio + count*val_ratio)],\n",
        "                            image8[int(count*train_ratio):int(count *\n",
        "                                                              train_ratio + count*val_ratio)],\n",
        "                            image9[int(count*train_ratio):int(count *\n",
        "                                                              train_ratio + count*val_ratio)],\n",
        "                            image10[int(count*train_ratio):int(count *\n",
        "                                                              train_ratio + count*val_ratio)],\n",
        "                            image11[int(count*train_ratio):int(count *\n",
        "                                                              train_ratio + count*val_ratio)]))\n",
        "    y_val_human = np.concatenate((label0_1[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label1_1[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label2_1[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label3_1[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label4_1[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label5_1[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label6_1[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label7_1[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label8_1[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label9_1[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label10_1[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label11_1[int(count*train_ratio):int(count*train_ratio + count*val_ratio)]))\n",
        "    y_val_motion = np.concatenate((label0_2[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label1_2[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label2_2[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label3_2[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label4_2[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label5_2[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label6_2[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label7_2[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label8_2[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label9_2[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label10_2[int(count*train_ratio):int(count*train_ratio + count*val_ratio)],\n",
        "                            label11_2[int(count*train_ratio):int(count*train_ratio + count*val_ratio)]))\n",
        "    x_test = np.concatenate((image0[int(count*train_ratio + \n",
        "                                        count*val_ratio): count],\n",
        "                             image1[int(count*train_ratio +\n",
        "                                        count*val_ratio): count],\n",
        "                             image2[int(count*train_ratio +\n",
        "                                        count*val_ratio): count],\n",
        "                             image3[int(count*train_ratio +\n",
        "                                        count*val_ratio): count],\n",
        "                             image4[int(count*train_ratio +\n",
        "                                        count*val_ratio): count],\n",
        "                             image5[int(count*train_ratio +\n",
        "                                        count*val_ratio): count],\n",
        "                             image6[int(count*train_ratio +\n",
        "                                        count*val_ratio): count],\n",
        "                             image7[int(count*train_ratio + \n",
        "                                        count*val_ratio): count],\n",
        "                             image8[int(count*train_ratio + \n",
        "                                        count*val_ratio): count],\n",
        "                             image9[int(count*train_ratio + \n",
        "                                        count*val_ratio): count],\n",
        "                             image10[int(count*train_ratio + \n",
        "                                        count*val_ratio): count],\n",
        "                             image11[int(count*train_ratio + \n",
        "                                        count*val_ratio): count]))\n",
        "    y_test_human = np.concatenate((label0_1[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label1_1[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label2_1[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label3_1[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label4_1[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label5_1[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label6_1[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label7_1[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label8_1[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label9_1[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label10_1[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label11_1[int(count*train_ratio + count*val_ratio): count]))\n",
        "    y_test_motion = np.concatenate((label0_2[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label1_2[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label2_2[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label3_2[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label4_2[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label5_2[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label6_2[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label7_2[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label8_2[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label9_2[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label10_2[int(count*train_ratio + count*val_ratio): count],\n",
        "                             label11_2[int(count*train_ratio + count*val_ratio): count]))\n",
        "\n",
        "    train_gen = ImageDataGenerator(\n",
        "        width_shift_range=wsr\n",
        "    )\n",
        "    augment_size = int(augment_ratio * x_train.shape[0])\n",
        "    randidx = np.random.randint(x_train.shape[0], size=augment_size)\n",
        "    x_augmented = x_train[randidx].copy()\n",
        "    y_augmented_human = y_train_human[randidx].copy()\n",
        "    y_augmented_motion = y_train_motion[randidx].copy()\n",
        "    x_augmented, y_augmented_human = train_gen.flow(x_augmented, y_augmented_human, batch_size=augment_size, shuffle=False).next()\n",
        "    x_augmented, y_augmented_motion = train_gen.flow(x_augmented, y_augmented_motion, batch_size=augment_size, shuffle=False).next()\n",
        "    x_train = np.concatenate((x_train, x_augmented))\n",
        "    y_train_human = np.concatenate((y_train_human, y_augmented_human))\n",
        "    y_train_motion = np.concatenate((y_train_motion, y_augmented_motion))\n",
        "\n",
        "    s = np.arange(x_train.shape[0])\n",
        "    np.random.shuffle(s)\n",
        "    x_train = x_train[s]\n",
        "    y_train_human = y_train_human[s]\n",
        "    y_train_motion = y_train_motion[s]\n",
        "\n",
        "    s = np.arange(x_val.shape[0])\n",
        "    np.random.shuffle(s)\n",
        "    x_val = x_val[s]\n",
        "    y_val_human = y_val_human[s]\n",
        "    y_val_motion = y_val_motion[s]\n",
        "\n",
        "    s = np.arange(x_test.shape[0])\n",
        "    np.random.shuffle(s)\n",
        "    x_test = x_test[s]\n",
        "    y_test_human = y_test_human[s]\n",
        "    y_test_motion = y_test_motion[s]\n",
        "\n",
        "    return x_train, y_train_human, y_train_motion, x_val, y_val_human, y_val_motion, x_test, y_test_human, y_test_motion\n",
        "\n",
        "\n",
        "row_len = math.ceil((end_row - start_row))\n",
        "col_len = math.ceil((end_col - start_col))\n",
        "\n",
        "image1, label1_1, label1_2 = preprocessing(1, 0)\n",
        "image2, label2_1, label2_2 = preprocessing(1, 2)\n",
        "image3, label3_1, label3_2 = preprocessing(1, 3)\n",
        "image4, label4_1, label4_2 = preprocessing(2, 0)\n",
        "image5, label5_1, label5_2 = preprocessing(2, 2)\n",
        "image6, label6_1, label6_2 = preprocessing(2, 3)\n",
        "image7, label7_1, label7_2 = preprocessing(3, 0)\n",
        "image8, label8_1, label8_2 = preprocessing(3, 2)\n",
        "image9, label9_1, label9_2 = preprocessing(3, 3)\n",
        "image10, label10_1, label10_2 = preprocessing(4, 0)\n",
        "image11, label11_1, label11_2 = preprocessing(4, 2)\n",
        "image12, label12_1, label12_2 = preprocessing(4, 3)\n",
        "\n",
        "result_acc_1 = 0\n",
        "result_acc_2 = 0\n",
        "\n",
        "for i in range(try_num):\n",
        "    print(str(i + 1) + ' repeat')\n",
        "\n",
        "    # 순서를 섞음\n",
        "    s = np.arange(image1.shape[0])\n",
        "    np.random.shuffle(s)\n",
        "    image1_shuff = image1[s]\n",
        "\n",
        "    s = np.arange(image2.shape[0])\n",
        "    np.random.shuffle(s)\n",
        "    image2_shuff = image2[s]\n",
        "\n",
        "    s = np.arange(image3.shape[0])\n",
        "    np.random.shuffle(s)\n",
        "    image3_shuff = image3[s]\n",
        "\n",
        "    s = np.arange(image4.shape[0])\n",
        "    np.random.shuffle(s)\n",
        "    image4_shuff = image4[s]\n",
        "\n",
        "    s = np.arange(image5.shape[0])\n",
        "    np.random.shuffle(s)\n",
        "    image5_shuff = image5[s]\n",
        "\n",
        "    s = np.arange(image6.shape[0])\n",
        "    np.random.shuffle(s)\n",
        "    image6_shuff = image6[s]\n",
        "\n",
        "    s = np.arange(image7.shape[0])\n",
        "    np.random.shuffle(s)\n",
        "    image7_shuff = image7[s]\n",
        "\n",
        "    s = np.arange(image8.shape[0])\n",
        "    np.random.shuffle(s)\n",
        "    image8_shuff = image8[s]\n",
        "\n",
        "    s = np.arange(image9.shape[0])\n",
        "    np.random.shuffle(s)\n",
        "    image9_shuff = image9[s]\n",
        "\n",
        "    s = np.arange(image10.shape[0])\n",
        "    np.random.shuffle(s)\n",
        "    image10_shuff = image10[s]\n",
        "\n",
        "    s = np.arange(image11.shape[0])\n",
        "    np.random.shuffle(s)\n",
        "    image11_shuff = image11[s]\n",
        "\n",
        "    s = np.arange(image12.shape[0])\n",
        "    np.random.shuffle(s)\n",
        "    image12_shuff = image12[s]\n",
        "\n",
        "    # 크기에 맞게 자름\n",
        "    image1_crop = preprocessing_resize_crop(\n",
        "        image1_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
        "    image2_crop = preprocessing_resize_crop(\n",
        "        image2_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
        "    image3_crop = preprocessing_resize_crop(\n",
        "        image3_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
        "    image4_crop = preprocessing_resize_crop(\n",
        "        image4_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
        "    image5_crop = preprocessing_resize_crop(\n",
        "        image5_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
        "    image6_crop = preprocessing_resize_crop(\n",
        "        image6_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
        "    image7_crop = preprocessing_resize_crop(\n",
        "        image7_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
        "    image8_crop = preprocessing_resize_crop(\n",
        "        image8_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
        "    image9_crop = preprocessing_resize_crop(\n",
        "        image9_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
        "    image10_crop = preprocessing_resize_crop(\n",
        "        image10_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
        "    image11_crop = preprocessing_resize_crop(\n",
        "        image11_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
        "    image12_crop = preprocessing_resize_crop(\n",
        "        image12_shuff, start_row, end_row, start_col, end_col, scale_row, scale_col)\n",
        "\n",
        "    # 자른 image를 각 data set으로 나눠서 합침\n",
        "    x_train, y_train_human, y_train_motion, x_val, y_val_human, y_val_motion, x_test, y_test_human, y_test_motion = concatenate_n_div(\n",
        "        image1_crop, label1_1, label1_2, image2_crop, label2_1, label2_2, image3_crop, label3_1, label3_2, image4_crop, label4_1, label4_2, image5_crop, label5_1, label5_2, image6_crop, label6_1, label6_2, image7_crop, label7_1, label7_2, image8_crop, label8_1, label8_2, image9_crop, label9_1, label9_2, image10_crop, label10_1, label10_2, image11_crop, label11_1, label11_2, image12_crop, label12_1, label12_2)\n",
        "\n",
        "    maxval = x_train.max()\n",
        "    if maxval < x_val.max():\n",
        "        maxval = x_val.max()\n",
        "    if maxval < x_test.max():\n",
        "        maxval = x_test.max()\n",
        "\n",
        "    # 정규화\n",
        "    x_train = x_train.astype('float32')/maxval\n",
        "    x_val = x_val.astype('float32')/maxval\n",
        "    x_test = x_test.astype('float32')/maxval\n",
        "\n",
        "    model = create_CNNmodel(classnum_human, classnum_motion, lr, row_len, col_len)\n",
        "    if i == 0:\n",
        "        print(model.summary())\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_human_output_accuracy', patience=10)\n",
        "    y_train_human = np_utils.to_categorical(y_train_human, classnum_human)\n",
        "    y_train_motion = np_utils.to_categorical(y_train_motion, classnum_motion)\n",
        "    y_val_human = np_utils.to_categorical(y_val_human, classnum_human)\n",
        "    y_val_motion = np_utils.to_categorical(y_val_motion, classnum_motion)\n",
        "    y_test_human = np_utils.to_categorical(y_test_human, classnum_human)\n",
        "    y_test_motion = np_utils.to_categorical(y_test_motion, classnum_motion)\n",
        "    hist = model.fit({'main_input': x_train}, {'human_output': y_train_human, 'motion_output': y_train_motion}, \n",
        "    validation_data=(x_val, [y_val_human, y_val_motion]), epochs=50, verbose=0, callbacks=[early_stopping], batch_size=bs)\n",
        "    \n",
        "    # 평가\n",
        "    # print('Evaluate')\n",
        "    score = model.evaluate(x_test, [y_test_human, y_test_motion])\n",
        "    result_acc_1 = result_acc_1 + score[3]    # 정확도 결과 저장하여 평균값 내는데 사용\n",
        "    result_acc_2 = result_acc_2 + score[4]    # 정확도 결과 저장하여 평균값 내는데 사용\n",
        "\n",
        "    test_label_human = np.concatenate((test_label_human, y_test_human))\n",
        "    test_label_motion = np.concatenate((test_label_motion, y_test_motion))\n",
        "    pred = model.predict(x_test)\n",
        "    predict_label_human = np.concatenate((predict_label_human, pred[0]))\n",
        "    predict_label_motion = np.concatenate((predict_label_motion, pred[1]))\n",
        "\n",
        "print('image size :', str(row_len)+'X'+str(col_len), '   row =', str(start_row)+' : '+str(end_row), '   col =', str(start_col)+' : '+str(end_col),\n",
        "      '   round :', try_num, '//  average_acc_human :', result_acc_1 / try_num, 'average_acc_motion :', result_acc_2 / try_num)\n",
        "\n",
        "test_label_human = np.delete(test_label_human, 0, axis=0)\n",
        "test_label_motion = np.delete(test_label_motion, 0, axis=0)\n",
        "predict_label_human = np.delete(predict_label_human, 0, axis=0)\n",
        "predict_label_motion = np.delete(predict_label_motion, 0, axis=0)\n",
        "\n",
        "sns.set(style='white')\n",
        "plt.figure(figsize=(classnum_human, classnum_human))\n",
        "cm = confusion_matrix(np.argmax(test_label_human[:int(test_label_human.shape[0])], axis=1),\n",
        "                      np.argmax(predict_label_human[:int(predict_label_human.shape[0])], axis=-1))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "sns.set(style='white')\n",
        "plt.figure(figsize=(classnum_motion, classnum_motion))\n",
        "cm = confusion_matrix(np.argmax(test_label_motion[:int(test_label_motion.shape[0])], axis=1),\n",
        "                      np.argmax(predict_label_motion[:int(predict_label_motion.shape[0])], axis=-1))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "print(model.summary())"
      ],
      "outputs": [],
      "metadata": {
        "id": "EYXGOazytzsY"
      }
    }
  ]
}